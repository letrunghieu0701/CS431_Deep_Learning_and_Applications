{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the below line in Jupyter Notebook to view the plot with interactive window, it doesn't work in Google Colab\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_blue = 80\n",
    "n_sample_red = 50\n",
    "n_sample = n_sample_red + n_sample_blue\n",
    "\n",
    "x_center_blue = np.array([[-6], [9]])\n",
    "x_center_red = np.array([[1], [2]])\n",
    "x_blue = x_center_blue + np.random.normal(0, 1, size=(2, n_sample_blue))\n",
    "x_red = x_center_red + np.random.normal(0, 1, size=(2, n_sample_red))\n",
    "ones = np.ones(n_sample)\n",
    "x = np.hstack((x_blue, x_red))\n",
    "X = np.vstack((ones, x))\n",
    "\n",
    "Y = np.hstack((np.ones(n_sample_blue), np.zeros(n_sample_red)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 130)\n",
      "Y.shape: (130,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_blue[0][:], x_blue[1][:], 'bo')\n",
    "plt.plot(x_red[0][:], x_red[1][:], 'ro')\n",
    "# Or\n",
    "# plt.plot(X[1][:n_sample_blue], X[2][:n_sample_blue], 'bo')\n",
    "# plt.plot(X[1][n_sample_blue:], X[2][n_sample_blue:], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set value for these parameters:<br>\n",
    "theta0, theta1, theta2, alpha and epsilon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([[2.0], [-6.0], [7.0]]) # theta order: 0 1 2\n",
    "alpha = 0.01\n",
    "epsilon = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop:**<br>\n",
    "<span style=\"margin-left:2em\">Update theta</span><br>\n",
    "<span style=\"margin-left:2em\">Stopping condition</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 130)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(theta.T, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: (42.778224575672056, 16.876902791171105, 78.14601934690161)\n",
      "Epoch: 2 Loss: (40.0886917951199, 13.235818908659612, 74.37045400060502)\n",
      "Epoch: 3 Loss: (36.5104256341927, 8.84122798283604, 69.0455365891811)\n",
      "Epoch: 4 Loss: (32.67565721051012, 4.977693954154058, 63.28994329361258)\n",
      "Epoch: 5 Loss: (27.954706884257405, -0.2632378107405745, 53.71873917487237)\n",
      "Epoch: 6 Loss: (24.334208621645214, -3.95503233534902, 46.32408084778037)\n",
      "Epoch: 7 Loss: (22.200303401669906, -5.411890079904111, 42.83173908352519)\n",
      "Epoch: 8 Loss: (20.51050882657041, -6.18284819869008, 40.14450552798718)\n",
      "Epoch: 9 Loss: (18.690724627076957, -6.791762743687371, 36.54158294111427)\n",
      "Epoch: 10 Loss: (16.3737968208, -7.4539265764119955, 30.815813257889726)\n",
      "Epoch: 11 Loss: (14.094727642819278, -7.937978293688826, 25.04128602617959)\n",
      "Epoch: 12 Loss: (12.323840216165655, -8.136748353813015, 20.860715985467944)\n",
      "Epoch: 13 Loss: (10.996383983335376, -8.185396400594493, 17.916831551056593)\n",
      "Epoch: 14 Loss: (10.010485802952228, -8.168492016317241, 15.832642744869817)\n",
      "Epoch: 15 Loss: (9.274364998161857, -8.120167549866274, 14.344284036854498)\n",
      "Epoch: 16 Loss: (8.71037619537305, -8.052289076386746, 13.252801353636125)\n",
      "Epoch: 17 Loss: (8.259471515804497, -7.9670068866325705, 12.413645262850768)\n",
      "Epoch: 18 Loss: (7.878542576386487, -7.861893118362303, 11.722824375708045)\n",
      "Epoch: 19 Loss: (7.536259314082372, -7.732424568324278, 11.10407814771043)\n",
      "Epoch: 20 Loss: (7.210400287343288, -7.573998558276613, 10.50194815847649)\n",
      "Epoch: 21 Loss: (6.887236472665262, -7.384458339414916, 9.88153065728566)\n",
      "Epoch: 22 Loss: (6.562068984725463, -7.166749384769983, 9.23194995191524)\n",
      "Epoch: 23 Loss: (6.2386741835720425, -6.92968256694638, 8.566117609087664)\n",
      "Epoch: 24 Loss: (5.9257173713869475, -6.6848059108858875, 7.9098179692108905)\n",
      "Epoch: 25 Loss: (5.63116543137171, -6.4402736024271015, 7.282407374957031)\n",
      "Epoch: 26 Loss: (5.357906733306919, -6.194800602609284, 6.678527116811658)\n",
      "Epoch: 27 Loss: (5.102178444925999, -5.933340341420844, 6.055820970302317)\n",
      "Epoch: 28 Loss: (4.854293166922494, -5.625428487443182, 5.330707731197591)\n",
      "Epoch: 29 Loss: (4.60245700337821, -5.233111224247804, 4.399968435982536)\n",
      "Epoch: 30 Loss: (4.342492529748153, -4.741247454366966, 3.2213664533182076)\n",
      "Epoch: 31 Loss: (4.088501014182787, -4.196326863780786, 1.9145021887604015)\n",
      "Epoch: 32 Loss: (3.8666075602630325, -3.6923736873174606, 0.7195268820241317)\n",
      "Epoch: 33 Loss: (3.6935036506088683, -3.3006684511911204, -0.1867625878434726)\n",
      "Epoch: 34 Loss: (3.567472819773756, -3.033074643565085, -0.7798741407107304)\n",
      "Epoch: 35 Loss: (3.476528800754825, -2.8631469848778446, -1.1292933597285006)\n",
      "Epoch: 36 Loss: (3.408029477436543, -2.757148256524697, -1.3202015989931146)\n",
      "Epoch: 37 Loss: (3.3526871414131696, -2.688828629461209, -1.4179201612748569)\n",
      "Epoch: 38 Loss: (3.3047194125993458, -2.6414311220605082, -1.4638477294792807)\n",
      "Epoch: 39 Loss: (3.2608223719133025, -2.605258516911119, -1.481853649959061)\n",
      "Epoch: 40 Loss: (3.2191936039328266, -2.574979552537352, -1.4850422836256916)\n",
      "Epoch: 41 Loss: (3.178875416792161, -2.5477430672620867, -1.4804272602389634)\n",
      "Epoch: 42 Loss: (3.1393678595054313, -2.522048438963363, -1.4717142359519022)\n",
      "Epoch: 43 Loss: (3.100414260537969, -2.4971148308862983, -1.4608493673468355)\n",
      "Epoch: 44 Loss: (3.0618859291692475, -2.472540843047959, -1.4488528521020503)\n",
      "Epoch: 45 Loss: (3.023721109186813, -2.448123997525919, -1.436260172695581)\n",
      "Epoch: 46 Loss: (2.9858928999826015, -2.4237658142863543, -1.4233537069379065)\n",
      "Epoch: 47 Loss: (2.948392455773379, -2.399422094887575, -1.4102837963802235)\n",
      "Epoch: 48 Loss: (2.9112201935511393, -2.375076921202359, -1.3971319107061975)\n",
      "Epoch: 49 Loss: (2.874381186925808, -2.3507290539328576, -1.3839435771935482)\n",
      "Epoch: 50 Loss: (2.837882745284248, -2.3263848060453776, -1.3707455437649805)\n",
      "Epoch: 51 Loss: (2.801733133810999, -2.302054296721403, -1.3575547230401928)\n",
      "Epoch: 52 Loss: (2.7659408897015876, -2.2777494714222453, -1.3443828508303959)\n",
      "Epoch: 53 Loss: (2.730514450696875, -2.2534830460284927, -1.3312389089087717)\n",
      "Epoch: 54 Loss: (2.6954619480612245, -2.2292679357935317, -1.3181303807716196)\n",
      "Epoch: 55 Loss: (2.660791087024841, -2.20511693987766, -1.3050638980334726)\n",
      "Epoch: 56 Loss: (2.6265090746634217, -2.1810425617741864, -1.2920455687443915)\n",
      "Epoch: 57 Loss: (2.5926225744365095, -2.1570569030937112, -1.279081139987669)\n",
      "Epoch: 58 Loss: (2.5591376766157574, -2.133171597999126, -1.2661760745729023)\n",
      "Epoch: 59 Loss: (2.526059879021554, -2.109397771146728, -1.253335583706944)\n",
      "Epoch: 60 Loss: (2.493394075156158, -2.0857460101018086, -1.2405646376554436)\n",
      "Epoch: 61 Loss: (2.461144548177885, -2.062226347417191, -1.2278679659767153)\n",
      "Epoch: 62 Loss: (2.4293149698348273, -2.038848249750148, -1.2152500534147226)\n",
      "Epoch: 63 Loss: (2.3979084037978, -2.0156206125179015, -1.2027151346331353)\n",
      "Epoch: 64 Loss: (2.366927312974321, -1.9925517591652067, -1.1902671894258672)\n",
      "Epoch: 65 Loss: (2.336373570439109, -1.9696494444045882, -1.1779099392113623)\n",
      "Epoch: 66 Loss: (2.3062484736294167, -1.9469208609317799, -1.1656468451687982)\n",
      "Epoch: 67 Loss: (2.2765527614503314, -1.9243726491884103, -1.153481108128159)\n",
      "Epoch: 68 Loss: (2.2472866339282183, -1.902010909779248, -1.1414156701896614)\n",
      "Epoch: 69 Loss: (2.2184497740459928, -1.8798412181712207, -1.1294532179726333)\n",
      "Epoch: 70 Loss: (2.1900413713946825, -1.8578686413178291, -1.1175961873508125)\n",
      "Epoch: 71 Loss: (2.1620601472820424, -1.8360977558672626, -1.1058467695101792)\n",
      "Epoch: 72 Loss: (2.1345043809512143, -1.8145326676301552, -1.0942069181550858)\n",
      "Epoch: 73 Loss: (2.1073719365795314, -1.7931770320026774, -1.0826783576864722)\n",
      "Epoch: 74 Loss: (2.080660290748666, -1.772034075062234, -1.0712625921797903)\n",
      "Epoch: 75 Loss: (2.054366560101648, -1.7511066150770378, -1.0599609149969331)\n",
      "Epoch: 76 Loss: (2.0284875289287085, -1.7303970841957639, -1.0487744188758907)\n",
      "Epoch: 77 Loss: (2.003019676451559, -1.709907550108855, -1.037704006353478)\n",
      "Epoch: 78 Loss: (1.9779592036039637, -1.6896397374987397, -1.0267504003885015)\n",
      "Epoch: 79 Loss: (1.953302059134408, -1.6695950491211684, -1.0159141550661341)\n",
      "Epoch: 80 Loss: (1.9290439648840174, -1.6497745863841926, -1.005195666277074)\n",
      "Epoch: 81 Loss: (1.9051804401189243, -1.630179169314181, -0.9945951822785698)\n",
      "Epoch: 82 Loss: (1.8817068248208262, -1.6108093558195948, -0.9841128140573308)\n",
      "Epoch: 83 Loss: (1.858618301862322, -1.5916654601832547, -0.9737485454263866)\n",
      "Epoch: 84 Loss: (1.8359099180143763, -1.5727475707316736, -0.9635022427998428)\n",
      "Epoch: 85 Loss: (1.813576603752127, -1.554055566646297, -0.9533736646002564)\n",
      "Epoch: 86 Loss: (1.7916131918419047, -1.5355891338956857, -0.9433624702635839)\n",
      "Epoch: 87 Loss: (1.7700144347071392, -1.517347780280641, -0.933468228815046)\n",
      "Epoch: 88 Loss: (1.7487750205833326, -1.4993308495943276, -0.9236904269987088)\n",
      "Epoch: 89 Loss: (1.7278895884832788, -1.4815375349095052, -0.9140284769493826)\n",
      "Epoch: 90 Loss: (1.707352742002583, -1.4639668910120154, -0.9044817234026661)\n",
      "Epoch: 91 Loss: (1.6871590620029222, -1.446617846006011, -0.8950494504445361)\n",
      "Epoch: 92 Loss: (1.667303118216378, -1.4294892121215261, -0.8857308878058548)\n",
      "Epoch: 93 Loss: (1.6477794798186112, -1.4125796957585814, -0.8765252167119217)\n",
      "Epoch: 94 Loss: (1.628582725021926, -1.3958879068048382, -0.8674315752996868)\n",
      "Epoch: 95 Loss: (1.6097074497414556, -1.379412367265683, -0.8584490636183908)\n",
      "Epoch: 96 Loss: (1.5911482753889081, -1.363151519246413, -0.8495767482313191)\n",
      "Epoch: 97 Loss: (1.5728998558488547, -1.3471037323272457, -0.8408136664371059)\n",
      "Epoch: 98 Loss: (1.5549568836921015, -1.331267310370602, -0.8321588301316308)\n",
      "Epoch: 99 Loss: (1.537314095680066, -1.315640497800643, -0.8236112293303833)\n",
      "Epoch: 100 Loss: (1.5199662776126222, -1.3002214853930627, -0.815169835372839)\n",
      "Epoch: 101 Loss: (1.5029082685702675, -1.2850084156122272, -0.8068336038298838)\n",
      "Epoch: 102 Loss: (1.4861349645994941, -1.2699993875311522, -0.7986014771348757)\n",
      "Epoch: 103 Loss: (1.4696413218879898, -1.2551924613677943, -0.790472386959134)\n",
      "Epoch: 104 Loss: (1.4534223594740183, -1.2405856626696041, -0.7824452563512758)\n",
      "Epoch: 105 Loss: (1.4374731615318124, -1.2261769861760685, -0.7745190016596287)\n",
      "Epoch: 106 Loss: (1.4217888792722477, -1.2119643993869007, -0.7666925342562572)\n",
      "Epoch: 107 Loss: (1.4063647324956803, -1.1979458458620416, -0.7589647620793035)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108 Loss: (1.3911960108311399, -1.1841192482769887, -0.7513345910106525)\n",
      "Epoch: 109 Loss: (1.3762780746937033, -1.1704825112555877, -0.7438009261040038)\n",
      "Epoch: 110 Loss: (1.3616063559894511, -1.1570335240003444, -0.7363626726777379)\n",
      "Epoch: 111 Loss: (1.347176358595065, -1.1437701627385788, -0.7290187372860568)\n",
      "Epoch: 112 Loss: (1.3329836586369017, -1.1306902930010474, -0.7217680285808373)\n",
      "Epoch: 113 Loss: (1.3190239045922953, -1.1177917717481136, -0.7146094580755753)\n",
      "Epoch: 114 Loss: (1.3052928172338065, -1.1050724493571353, -0.7075419408218769)\n",
      "Epoch: 115 Loss: (1.291786189435258, -1.0925301714831226, -0.70056439600828)\n",
      "Epoch: 116 Loss: (1.2784998858566516, -1.080162780803835, -0.693675747489952)\n",
      "Epoch: 117 Loss: (1.2654298425233825, -1.0679681186588568, -0.6868749242574275)\n",
      "Epoch: 118 Loss: (1.2525720663136768, -1.055944026591517, -0.68016086085143)\n",
      "Epoch: 119 Loss: (1.2399226343667689, -1.0440883478014478, -0.6735324977300939)\n",
      "Epoch: 120 Loss: (1.227477693422958, -1.0323989285143864, -0.6669887815948561)\n",
      "Epoch: 121 Loss: (1.2152334591056406, -1.0208736192756198, -0.6605286656795741)\n",
      "Epoch: 122 Loss: (1.203186215154143, -1.009510276172083, -0.6541511100080978)\n",
      "Epoch: 123 Loss: (1.191332312615387, -0.9983067619882989, -0.6478550816236213)\n",
      "Epoch: 124 Loss: (1.179668169001286, -0.987260947299736, -0.6416395547943423)\n",
      "Epoch: 125 Loss: (1.1681902674182036, -0.9763707115078648, -0.6355035111976148)\n",
      "Epoch: 126 Loss: (1.1568951556738456, -0.9656339438197026, -0.6294459400860837)\n",
      "Epoch: 127 Loss: (1.145779445366437, -0.9550485441749179, -0.6234658384378745)\n",
      "Epoch: 128 Loss: (1.1348398109603999, -0.9446124241230457, -0.6175622110927727)\n",
      "Epoch: 129 Loss: (1.1240729888521652, -0.9343235076529415, -0.6117340708765806)\n",
      "Epoch: 130 Loss: (1.1134757764293606, -0.9241797319766017, -0.6059804387147472)\n",
      "Epoch: 131 Loss: (1.103045031126127, -0.9141790482690926, -0.6003003437368346)\n",
      "Epoch: 132 Loss: (1.0927776694769598, -0.9043194223661668, -0.5946928233728447)\n",
      "Epoch: 133 Loss: (1.0826706661711787, -0.8945988354212485, -0.589156923442105)\n",
      "Epoch: 134 Loss: (1.0727210531097362, -0.8850152845228108, -0.5836916982359418)\n",
      "Epoch: 135 Loss: (1.0629259184659627, -0.8755667832737901, -0.5782962105941364)\n",
      "Epoch: 136 Loss: (1.0532824057514614, -0.866251362333847, -0.5729695319762717)\n",
      "Epoch: 137 Loss: (1.0437877128883035, -0.8570670699258598, -0.5677107425278943)\n",
      "Epoch: 138 Loss: (1.0344390912884174, -0.8480119723075399, -0.5625189311421157)\n",
      "Epoch: 139 Loss: (1.0252338449409617, -0.839084154209278, -0.5573931955166859)\n",
      "Epoch: 140 Loss: (1.0161693295083007, -0.8302817192391245, -0.5523326422069006)\n",
      "Epoch: 141 Loss: (1.0072429514311332, -0.8216027902558927, -0.547336386674404)\n",
      "Epoch: 142 Loss: (0.9984521670432145, -0.813045509711384, -0.5424035533318603)\n",
      "Epoch: 143 Loss: (0.9897944816960071, -0.8046080399625513, -0.5375332755837741)\n",
      "Epoch: 144 Loss: (0.9812674488935387, -0.7962885635545247, -0.5327246958634476)\n",
      "Epoch: 145 Loss: (0.9728686694377298, -0.7880852834755631, -0.5279769656658682)\n",
      "Epoch: 146 Loss: (0.9645957905843136, -0.7799964233846146, -0.5232892455768526)\n",
      "Epoch: 147 Loss: (0.956446505209507, -0.7720202278125189, -0.5186607052982964)\n",
      "Epoch: 148 Loss: (0.9484185509875248, -0.7641549623377369, -0.5140905236694401)\n",
      "Epoch: 149 Loss: (0.9405097095789818, -0.756398913737423, -0.509577888684373)\n",
      "Epoch: 150 Loss: (0.9327178058302515, -0.7487503901148225, -0.5051219975055277)\n",
      "Epoch: 151 Loss: (0.9250407069837792, -0.7412077210038667, -0.500722056473254)\n",
      "Epoch: 152 Loss: (0.9174763218993358, -0.7337692574517151, -0.4963772811116341)\n",
      "Epoch: 153 Loss: (0.9100226002862488, -0.7264333720803452, -0.4920868961301985)\n",
      "Epoch: 154 Loss: (0.9026775319465323, -0.7191984591278815, -0.4878501354218817)\n",
      "Epoch: 155 Loss: (0.8954391460289053, -0.712062934470528, -0.48366624205712555)\n",
      "Epoch: 156 Loss: (0.8883055102936728, -0.7050252356261737, -0.4795344682739812)\n",
      "Epoch: 157 Loss: (0.8812747303883796, -0.6980838217401433, -0.47545407546465)\n",
      "Epoch: 158 Loss: (0.8743449491342181, -0.6912371735542617, -0.47142433415813334)\n",
      "Epoch: 159 Loss: (0.8675143458231406, -0.6844837933599354, -0.46744452399908876)\n",
      "Epoch: 160 Loss: (0.8607811355255589, -0.6778222049359168, -0.4635139337233114)\n",
      "Epoch: 161 Loss: (0.8541435684086459, -0.6712509534717904, -0.4596318611293795)\n",
      "Epoch: 162 Loss: (0.847599929065112, -0.6647686054778046, -0.455797613046891)\n",
      "Epoch: 163 Loss: (0.8411485358524041, -0.6583737486817177, -0.45201050530143055)\n",
      "Epoch: 164 Loss: (0.8347877402422854, -0.652064991913683, -0.4482698626759563)\n",
      "Epoch: 165 Loss: (0.8285159261806846, -0.6458409649795932, -0.44457501886915085)\n",
      "Epoch: 166 Loss: (0.8223315094577697, -0.6397003185237932, -0.44092531645051436)\n",
      "Epoch: 167 Loss: (0.8162329370881412, -0.6336417238816621, -0.4373201068125999)\n",
      "Epoch: 168 Loss: (0.8102186867011284, -0.6276638729229961, -0.43375875012004245)\n",
      "Epoch: 169 Loss: (0.8042872659410243, -0.6217654778864791, -0.4302406152561011)\n",
      "Epoch: 170 Loss: (0.7984372118772697, -0.6159452712062151, -0.4267650797662267)\n",
      "Epoch: 171 Loss: (0.7926670904244328, -0.6102020053306223, -0.42333152979926536)\n",
      "Epoch: 172 Loss: (0.7869754957719632, -0.604534452534563, -0.41993936004596133)\n",
      "Epoch: 173 Loss: (0.7813610498235839, -0.5989414047249471, -0.4165879736753423)\n",
      "Epoch: 174 Loss: (0.7758224016462688, -0.5934216732406018, -0.41327678226875936)\n",
      "Epoch: 175 Loss: (0.7703582269287232, -0.5879740886468436, -0.410005205751783)\n",
      "Epoch: 176 Loss: (0.7649672274492542, -0.5825975005251921, -0.40677267232416364)\n",
      "Epoch: 177 Loss: (0.7596481305529553, -0.5772907772587647, -0.40357861838793896)\n",
      "Epoch: 178 Loss: (0.7543996886381288, -0.5720528058138079, -0.40042248847367484)\n",
      "Epoch: 179 Loss: (0.749220678651814, -0.5668824915177352, -0.3973037351652328)\n",
      "Epoch: 180 Loss: (0.7441099015943792, -0.561778757834182, -0.39422181902284886)\n",
      "Epoch: 181 Loss: (0.7390661820330343, -0.5567405461353832, -0.39117620850489676)\n",
      "Epoch: 182 Loss: (0.7340883676241945, -0.551766815472316, -0.3881663798883207)\n",
      "Epoch: 183 Loss: (0.7291753286445927, -0.5468565423429415, -0.3851918171878567)\n",
      "Epoch: 184 Loss: (0.7243259575310195, -0.5420087204587962, -0.382252012074286)\n",
      "Epoch: 185 Loss: (0.7195391684286484, -0.5372223605105714, -0.37934646379139364)\n",
      "Epoch: 186 Loss: (0.7148138967477375, -0.5324964899324025, -0.37647467907255183)\n",
      "Epoch: 187 Loss: (0.7101490987287397, -0.5278301526658891, -0.3736361720559542)\n",
      "Epoch: 188 Loss: (0.7055437510155825, -0.5232224089234169, -0.3708304641996833)\n",
      "Epoch: 189 Loss: (0.7009968502371293, -0.518672334951615, -0.3680570841957463)\n",
      "Epoch: 190 Loss: (0.696507412596622, -0.514179022794778, -0.3653155678838878)\n",
      "Epoch: 191 Loss: (0.6920744734690514, -0.5097415800586779, -0.3626054581649102)\n",
      "Epoch: 192 Loss: (0.687697087006332, -0.5053591296749742, -0.35992630491360256)\n",
      "Epoch: 193 Loss: (0.6833743257501718, -0.5010308096663387, -0.35727766489150736)\n",
      "Epoch: 194 Loss: (0.6791052802525288, -0.49675577291259293, -0.35465910165936976)\n",
      "Epoch: 195 Loss: (0.6748890587035361, -0.4925331869179016, -0.35207018548966273)\n",
      "Epoch: 196 Loss: (0.6707247865668026, -0.48836223357929537, -0.34951049327892136)\n",
      "Epoch: 197 Loss: (0.6666116062219578, -0.484242108956615, -0.346979608460218)\n",
      "Epoch: 198 Loss: (0.6625486766143548, -0.48017202304406975, -0.34447712091561383)\n",
      "Epoch: 199 Loss: (0.6585351729117866, -0.4761511995434272, -0.3420026268889291)\n",
      "Epoch: 200 Loss: (0.6545702861681402, -0.47217887563911215, -0.33955572889859037)\n",
      "Epoch: 201 Loss: (0.6506532229938535, -0.46825430177517885, -0.3371360356508133)\n",
      "Epoch: 202 Loss: (0.64678320523308, -0.46437674143440305, -0.3347431619530688)\n",
      "Epoch: 203 Loss: (0.6429594696474281, -0.4605454709193892, -0.33237672862798723)\n",
      "Epoch: 204 Loss: (0.6391812676061936, -0.45675977913597504, -0.33003636242763423)\n",
      "Epoch: 205 Loss: (0.6354478647829591, -0.45301896737893, -0.32772169594822936)\n",
      "Epoch: 206 Loss: (0.6317585408584444, -0.44932234911993724, -0.3254323675454516)\n",
      "Epoch: 207 Loss: (0.6281125892295246, -0.4456692497980989, -0.3231680212501714)\n",
      "Epoch: 208 Loss: (0.6245093167242767, -0.44205900661283504, -0.3209283066848596)\n",
      "Epoch: 209 Loss: (0.6209480433229662, -0.4384909683193314, -0.3187128789805963)\n",
      "Epoch: 210 Loss: (0.6174281018848663, -0.43496449502655526, -0.3165213986946916)\n",
      "Epoch: 211 Loss: (0.6139488378808016, -0.4314789579979076, -0.31435353172896696)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 212 Loss: (0.6105096091313067, -0.4280337394544656, -0.3122089492487782)\n",
      "Epoch: 213 Loss: (0.6071097855502924, -0.42462823238086944, -0.3100873276028077)\n",
      "Epoch: 214 Loss: (0.603748748894141, -0.42126184033397845, -0.3079883482434894)\n",
      "Epoch: 215 Loss: (0.6004258925160946, -0.4179339772541526, -0.3059116976482837)\n",
      "Epoch: 216 Loss: (0.5971406211258596, -0.4146440672792692, -0.3038570672417405)\n",
      "Epoch: 217 Loss: (0.5938923505543141, -0.41139154456148375, -0.3018241533183718)\n",
      "Epoch: 218 Loss: (0.5906805075232342, -0.40817585308670407, -0.29981265696629295)\n",
      "Epoch: 219 Loss: (0.5875045294199126, -0.40499644649676614, -0.2978222839918305)\n",
      "Epoch: 220 Loss: (0.5843638640766253, -0.4018527879144402, -0.29585274484478546)\n",
      "Epoch: 221 Loss: (0.5812579695547837, -0.3987443497710658, -0.293903754544748)\n",
      "Epoch: 222 Loss: (0.5781863139337325, -0.39567061363693873, -0.2919750326081958)\n",
      "Epoch: 223 Loss: (0.5751483751040765, -0.39263107005442116, -0.2900663029764978)\n",
      "Epoch: 224 Loss: (0.5721436405654493, -0.38962521837375885, -0.28817729394477626)\n",
      "Epoch: 225 Loss: (0.5691716072286426, -0.3866525665916095, -0.28630773809162924)\n",
      "Epoch: 226 Loss: (0.5662317812219688, -0.38371263119211657, -0.28445737220997797)\n",
      "Epoch: 227 Loss: (0.5633236777018511, -0.380804936990864, -0.282625937238414)\n",
      "Epoch: 228 Loss: (0.5604468206674382, -0.3779290169811789, -0.28081317819394075)\n",
      "Epoch: 229 Loss: (0.5576007427792944, -0.37508441218337935, -0.279018844105103)\n",
      "Epoch: 230 Loss: (0.5547849851819411, -0.372270671496264, -0.2772426879465547)\n",
      "Epoch: 231 Loss: (0.5519990973303026, -0.3694873515515098, -0.2754844665740204)\n",
      "Epoch: 232 Loss: (0.5492426368198491, -0.3667340165702865, -0.2737439406606676)\n",
      "Epoch: 233 Loss: (0.546515169220471, -0.36401023822266465, -0.2720208746339569)\n",
      "Epoch: 234 Loss: (0.5438162679139289, -0.36131559548938136, -0.2703150366136093)\n",
      "Epoch: 235 Loss: (0.5411455139348227, -0.3586496745260319, -0.2686261983505134)\n",
      "Epoch: 236 Loss: (0.538502495815025, -0.35601206852978523, -0.26695413516641064)\n",
      "Epoch: 237 Loss: (0.5358868094314833, -0.3534023776084566, -0.26529862589453457)\n",
      "Epoch: 238 Loss: (0.5332980578573272, -0.35082020865196445, -0.26365945282113085)\n",
      "Epoch: 239 Loss: (0.5307358512162018, -0.3482651752061295, -0.26203640162784647)\n",
      "Epoch: 240 Loss: (0.528199806539766, -0.34573689734876634, -0.26042926133506483)\n",
      "Epoch: 241 Loss: (0.5256895476282851, -0.3432350015680756, -0.25883782424601387)\n",
      "Epoch: 242 Loss: (0.5232047049142489, -0.34075912064330044, -0.25726188589180204)\n",
      "Epoch: 243 Loss: (0.5207449153289443, -0.3383088935275581, -0.2557012449773068)\n",
      "Epoch: 244 Loss: (0.5183098221719306, -0.3358839652328887, -0.25415570332789744)\n",
      "Epoch: 245 Loss: (0.515899074983335, -0.33348398671742113, -0.25262506583704386)\n",
      "Epoch: 246 Loss: (0.5135123294189295, -0.3311086147746939, -0.25110914041470384)\n",
      "Epoch: 247 Loss: (0.5111492471279079, -0.32875751192504704, -0.24960773793657784)\n",
      "Epoch: 248 Loss: (0.5088094956333133, -0.32643034630906514, -0.24812067219416684)\n",
      "Epoch: 249 Loss: (0.5064927482150566, -0.32412679158304475, -0.2466477598456346)\n",
      "Epoch: 250 Loss: (0.5041986837954621, -0.3218465268164303, -0.24518882036753495)\n",
      "Epoch: 251 Loss: (0.5019269868272974, -0.3195892363912512, -0.24374367600720842)\n",
      "Epoch: 252 Loss: (0.4996773471842144, -0.3173546099034076, -0.24231215173612664)\n",
      "Epoch: 253 Loss: (0.49744946005356894, -0.31514234206594544, -0.2408940752038384)\n",
      "Epoch: 254 Loss: (0.49524302583154234, -0.3129521326140776, -0.23948927669283704)\n",
      "Epoch: 255 Loss: (0.4930577500205396, -0.31078368621214686, -0.23809758907404555)\n",
      "Epoch: 256 Loss: (0.4908933431287841, -0.30863671236227114, -0.2367188477631866)\n",
      "Epoch: 257 Loss: (0.4887495205720927, -0.30651092531485946, -0.23535289067774295)\n",
      "Epoch: 258 Loss: (0.4866260025777428, -0.3044060439807359, -0.2339995581948283)\n",
      "Epoch: 259 Loss: (0.4845225140904374, -0.30232179184514407, -0.2326586931095046)\n",
      "Epoch: 260 Loss: (0.48243878468025575, -0.30025789688320165, -0.23133014059413484)\n",
      "Epoch: 261 Loss: (0.48037454845260263, -0.29821409147716993, -0.2300137481581881)\n",
      "Epoch: 262 Loss: (0.4783295439600837, -0.29619011233525866, -0.22870936560881963)\n",
      "Epoch: 263 Loss: (0.47630351411626615, -0.2941857004120345, -0.22741684501211462)\n",
      "Epoch: 264 Loss: (0.47429620611128476, -0.29220060083037064, -0.226136040655008)\n",
      "Epoch: 265 Loss: (0.472307371329245, -0.2902345628048803, -0.2248668090079292)\n",
      "Epoch: 266 Loss: (0.4703367652674062, -0.2882873395669419, -0.2236090086879237)\n",
      "Epoch: 267 Loss: (0.46838414745707624, -0.2863586882911318, -0.22236250042254138)\n",
      "Epoch: 268 Loss: (0.4664492813861823, -0.2844483700230368, -0.22112714701440578)\n",
      "Epoch: 269 Loss: (0.4645319344235084, -0.28255614960859615, -0.21990281330624856)\n",
      "Epoch: 270 Loss: (0.462631877744526, -0.2806817956247477, -0.21868936614666082)\n",
      "Epoch: 271 Loss: (0.46074888625880905, -0.2788250803114592, -0.21748667435639238)\n",
      "Epoch: 272 Loss: (0.45888273853897754, -0.2769857795050898, -0.21629460869528871)\n",
      "Epoch: 273 Loss: (0.457033216751148, -0.27516367257302976, -0.21511304182979396)\n",
      "Epoch: 274 Loss: (0.45520010658686033, -0.27335854234969587, -0.21394184830094046)\n",
      "Epoch: 275 Loss: (0.45338319719642073, -0.27157017507364184, -0.21278090449312637)\n",
      "Epoch: 276 Loss: (0.45158228112368115, -0.2697983603260966, -0.2116300886031004)\n",
      "Epoch: 277 Loss: (0.44979715424215694, -0.2680428909705186, -0.21048928060983768)\n",
      "Epoch: 278 Loss: (0.44802761569250615, -0.26630356309344017, -0.20935836224474635)\n",
      "Epoch: 279 Loss: (0.44627346782132077, -0.2645801759464835, -0.20823721696240133)\n",
      "Epoch: 280 Loss: (0.4445345161211801, -0.2628725318893817, -0.20712572991198794)\n",
      "Epoch: 281 Loss: (0.4428105691719882, -0.26118043633431415, -0.20602378790894707)\n",
      "Epoch: 282 Loss: (0.441101438583509, -0.25950369769116044, -0.20493127940739153)\n",
      "Epoch: 283 Loss: (0.4394069389391171, -0.25784212731394024, -0.20384809447283322)\n",
      "Epoch: 284 Loss: (0.43772688774069635, -0.2561955394481642, -0.20277412475559975)\n",
      "Epoch: 285 Loss: (0.43606110535472103, -0.2545637511794312, -0.20170926346440007)\n",
      "Epoch: 286 Loss: (0.43440941495941365, -0.25294658238279866, -0.20065340534070553)\n",
      "Epoch: 287 Loss: (0.43277164249301964, -0.25134385567325673, -0.19960644663340857)\n",
      "Epoch: 288 Loss: (0.43114761660315765, -0.24975539635722876, -0.1985682850738563)\n",
      "Epoch: 289 Loss: (0.42953716859718927, -0.24818103238485356, -0.19753881985156413)\n",
      "Epoch: 290 Loss: (0.42794013239363726, -0.24662059430333833, -0.19651795159013605)\n",
      "Epoch: 291 Loss: (0.4263563444745899, -0.24507391521118663, -0.1955055823237116)\n",
      "Epoch: 292 Loss: (0.42478564383908063, -0.2435408307132533, -0.19450161547386235)\n",
      "Epoch: 293 Loss: (0.42322787195742795, -0.2420211788767481, -0.19350595582684388)\n",
      "Epoch: 294 Loss: (0.421682872726514, -0.24051480018809032, -0.19251850951122454)\n",
      "Epoch: 295 Loss: (0.42015049242596125, -0.23902153751053162, -0.19153918397602818)\n",
      "Epoch: 296 Loss: (0.4186305796752173, -0.2375412360426843, -0.19056788796913907)\n",
      "Epoch: 297 Loss: (0.41712298539150783, -0.23607374327781866, -0.1896045315161425)\n",
      "Epoch: 298 Loss: (0.4156275627486295, -0.23461890896387383, -0.18864902589965876)\n",
      "Epoch: 299 Loss: (0.41414416713661056, -0.2331765850644261, -0.187701283638741)\n",
      "Epoch: 300 Loss: (0.4126726561221575, -0.23174662572024282, -0.18676121846893415)\n",
      "Epoch: 301 Loss: (0.4112128894099006, -0.23032888721158284, -0.18582874532265384)\n",
      "Epoch: 302 Loss: (0.4097647288044522, -0.22892322792138484, -0.18490378030966326)\n",
      "Epoch: 303 Loss: (0.40832803817318136, -0.22752950829892654, -0.18398624069829198)\n",
      "Epoch: 304 Loss: (0.4069026834097852, -0.2261475908244355, -0.18307604489654464)\n",
      "Epoch: 305 Loss: (0.4054885323985488, -0.22477733997416952, -0.18217311243393958)\n",
      "Epoch: 306 Loss: (0.4040854549793376, -0.2234186221862483, -0.1812773639434734)\n",
      "Epoch: 307 Loss: (0.402693322913301, -0.22207130582721407, -0.18038872114383633)\n",
      "Epoch: 308 Loss: (0.4013120098492267, -0.22073526115906308, -0.1795071068221836)\n",
      "Epoch: 309 Loss: (0.3999413912906013, -0.21941036030709526, -0.17863244481692273)\n",
      "Epoch: 310 Loss: (0.39858134456329386, -0.21809647722822884, -0.1777646600010477)\n",
      "Epoch: 311 Loss: (0.3972317487838897, -0.21679348767994513, -0.17690367826569203)\n",
      "Epoch: 312 Loss: (0.3958924848286673, -0.2155012691899639, -0.17604942650379998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 313 Loss: (0.39456343530315546, -0.21421970102627144, -0.17520183259439573)\n",
      "Epoch: 314 Loss: (0.39324448451231114, -0.21294866416787891, -0.1743608253869012)\n",
      "Epoch: 315 Loss: (0.3919355184312841, -0.21168804127610757, -0.17352633468576126)\n",
      "Epoch: 316 Loss: (0.3906364246767347, -0.21043771666632863, -0.17269829123547192)\n",
      "Epoch: 317 Loss: (0.38934709247873894, -0.20919757628037386, -0.17187662670567677)\n",
      "Epoch: 318 Loss: (0.388067412653225, -0.20796750765937036, -0.1710612736766667)\n",
      "Epoch: 319 Loss: (0.3867972775749488, -0.20674739991709268, -0.17025216562509393)\n",
      "Epoch: 320 Loss: (0.38553658115100037, -0.20553714371387005, -0.16944923690991243)\n",
      "Epoch: 321 Loss: (0.38428521879481503, -0.20433663123089962, -0.16865242275863704)\n",
      "Epoch: 322 Loss: (0.383043087400703, -0.20314575614515665, -0.16786165925371294)\n",
      "Epoch: 323 Loss: (0.38181008531885846, -0.20196441360467118, -0.16707688331922493)\n",
      "Epoch: 324 Loss: (0.3805861123308454, -0.2007925002042695, -0.1662980327078894)\n",
      "Epoch: 325 Loss: (0.3793710696255794, -0.1996299139618893, -0.1655250459880625)\n",
      "Epoch: 326 Loss: (0.3781648597757433, -0.19847655429517408, -0.16475786253120428)\n",
      "Epoch: 327 Loss: (0.3769673867146655, -0.19733232199858902, -0.16399642249947272)\n",
      "Epoch: 328 Loss: (0.37577855571365015, -0.19619711922098484, -0.16324066683344762)\n",
      "Epoch: 329 Loss: (0.37459827335971996, -0.19507084944349573, -0.1624905372402364)\n",
      "Epoch: 330 Loss: (0.37342644753380266, -0.19395341745793154, -0.16174597618161776)\n",
      "Epoch: 331 Loss: (0.3722629873893196, -0.19284472934552507, -0.16100692686248458)\n",
      "Epoch: 332 Loss: (0.37110780333117593, -0.1917446924560237, -0.1602733332195511)\n",
      "Epoch: 333 Loss: (0.3699608069951689, -0.1906532153872983, -0.1595451399100362)\n",
      "Epoch: 334 Loss: (0.3688219112277605, -0.18957020796518428, -0.15882229230078526)\n",
      "Epoch: 335 Loss: (0.3676910300662437, -0.18849558122375853, -0.15810473645745957)\n",
      "Epoch: 336 Loss: (0.36656807871929165, -0.18742924738604422, -0.15739241913381424)\n",
      "Epoch: 337 Loss: (0.3654529735478436, -0.18637111984489918, -0.15668528776141974)\n",
      "Epoch: 338 Loss: (0.3643456320463672, -0.18532111314437924, -0.1559832904393774)\n",
      "Epoch: 339 Loss: (0.3632459728244827, -0.18427914296146627, -0.15528637592413005)\n",
      "Epoch: 340 Loss: (0.36215391558889853, -0.18324512608800564, -0.1545944936196925)\n",
      "Epoch: 341 Loss: (0.3610693811257081, -0.1822189804130756, -0.15390759356784645)\n",
      "Epoch: 342 Loss: (0.35999229128300525, -0.18120062490564212, -0.15322562643857476)\n",
      "Epoch: 343 Loss: (0.35892256895381625, -0.18018997959747476, -0.15254854352072275)\n",
      "Epoch: 344 Loss: (0.3578601380593669, -0.17918696556651223, -0.15187629671261632)\n",
      "Epoch: 345 Loss: (0.35680492353262755, -0.17819150492033106, -0.15120883851313707)\n",
      "Epoch: 346 Loss: (0.35575685130219337, -0.17720352078011278, -0.15054612201262604)\n",
      "Epoch: 347 Loss: (0.3547158482764329, -0.176222937264721, -0.1498881008842424)\n",
      "Epoch: 348 Loss: (0.3536818423279462, -0.1752496794751983, -0.1492347293752209)\n",
      "Epoch: 349 Loss: (0.3526547622782975, -0.1742836734794712, -0.14858596229841783)\n",
      "Epoch: 350 Loss: (0.3516345378830281, -0.17332484629733835, -0.14794175502396942)\n",
      "Epoch: 351 Loss: (0.3506210998169388, -0.17237312588572115, -0.14730206347110011)\n",
      "Epoch: 352 Loss: (0.3496143796596504, -0.17142844112421396, -0.14666684409999678)\n",
      "Epoch: 353 Loss: (0.3486143098814093, -0.17049072180083358, -0.14603605390393604)\n",
      "Epoch: 354 Loss: (0.3476208238291659, -0.16955989859807735, -0.14540965040142573)\n",
      "Epoch: 355 Loss: (0.3466338557128918, -0.16863590307917092, -0.14478759162858162)\n",
      "Epoch: 356 Loss: (0.34565334059214886, -0.16771866767460383, -0.14416983613156079)\n",
      "Epoch: 357 Loss: (0.3446792143629008, -0.16680812566889247, -0.1435563429591258)\n",
      "Epoch: 358 Loss: (0.3437114137445549, -0.16590421118754728, -0.14294707165539347)\n",
      "Epoch: 359 Loss: (0.3427498762672491, -0.1650068591843439, -0.14234198225256084)\n",
      "Epoch: 360 Loss: (0.3417945402593376, -0.16411600542866933, -0.1417410352640149)\n",
      "Epoch: 361 Loss: (0.34084534483513174, -0.16323158649324943, -0.1411441916772664)\n",
      "Epoch: 362 Loss: (0.33990222988284685, -0.16235353974204336, -0.1405514129471125)\n",
      "Epoch: 363 Loss: (0.3389651360527462, -0.16148180331825468, -0.13996266098902996)\n",
      "Epoch: 364 Loss: (0.3380340047455218, -0.1606163161326914, -0.1393778981724743)\n",
      "Epoch: 365 Loss: (0.33710877810085965, -0.15975701785222535, -0.13879708731443832)\n",
      "Epoch: 366 Loss: (0.336189398986212, -0.1589038488884804, -0.13822019167307772)\n",
      "Epoch: 367 Loss: (0.3352758109857807, -0.1580567503867813, -0.13764717494132372)\n",
      "Epoch: 368 Loss: (0.33436795838966404, -0.157215664215146, -0.13707800124085817)\n",
      "Epoch: 369 Loss: (0.33346578618322487, -0.15638053295363877, -0.13651263511589462)\n",
      "Epoch: 370 Loss: (0.3325692400366179, -0.15555129988373734, -0.13595104152731202)\n",
      "Epoch: 371 Loss: (0.3316782662945178, -0.15472790897802374, -0.1353931858467219)\n",
      "Epoch: 372 Loss: (0.330792811966025, -0.1539103048900108, -0.13483903385060583)\n",
      "Epoch: 373 Loss: (0.32991282471472805, -0.1530984329440687, -0.13428855171475626)\n",
      "Epoch: 374 Loss: (0.32903825284895727, -0.1522922391255976, -0.13374170600860294)\n",
      "Epoch: 375 Loss: (0.3281690453122048, -0.1514916700713942, -0.13319846368965899)\n",
      "Epoch: 376 Loss: (0.32730515167369106, -0.15069667306005805, -0.13265879209821502)\n",
      "Epoch: 377 Loss: (0.3264465221191189, -0.1499071960027028, -0.13212265895189199)\n",
      "Epoch: 378 Loss: (0.32559310744156544, -0.14912318743370767, -0.1315900323404794)\n",
      "Epoch: 379 Loss: (0.3247448590325518, -0.14834459650175466, -0.13106088072064434)\n",
      "Epoch: 380 Loss: (0.32390172887323654, -0.14757137296085565, -0.13053517291097938)\n",
      "Epoch: 381 Loss: (0.32306366952577664, -0.1468034671616265, -0.13001287808698267)\n",
      "Epoch: 382 Loss: (0.32223063412484737, -0.14604083004276058, -0.12949396577600883)\n",
      "Epoch: 383 Loss: (0.32140257636927205, -0.1452834131224937, -0.12897840585259318)\n",
      "Epoch: 384 Loss: (0.3205794505138219, -0.14453116849031628, -0.12846616853361195)\n",
      "Epoch: 385 Loss: (0.31976121136115415, -0.14378404879886936, -0.12795722437350512)\n",
      "Epoch: 386 Loss: (0.3189478142538635, -0.14304200725582997, -0.1274515442597827)\n",
      "Epoch: 387 Loss: (0.31813921506667786, -0.14230499761598867, -0.12694909940849688)\n",
      "Epoch: 388 Loss: (0.31733537019880803, -0.1415729741735957, -0.1264498613596061)\n",
      "Epoch: 389 Loss: (0.3165362365663855, -0.14084589175459433, -0.12595380197273695)\n",
      "Epoch: 390 Loss: (0.3157417715950555, -0.14012370570917032, -0.1254608934227676)\n",
      "Epoch: 391 Loss: (0.31495193321268267, -0.13940637190434, -0.12497110819557225)\n",
      "Epoch: 392 Loss: (0.3141666798421782, -0.13869384671667762, -0.12448441908384221)\n",
      "Epoch: 393 Loss: (0.31338597039444815, -0.13798608702515097, -0.12400079918294316)\n",
      "Epoch: 394 Loss: (0.31260976426145626, -0.13728305020409254, -0.12352022188685226)\n",
      "Epoch: 395 Loss: (0.31183802130940486, -0.1365846941162805, -0.12304266088413043)\n",
      "Epoch: 396 Loss: (0.31107070187202995, -0.13589097710615228, -0.12256809015395709)\n",
      "Epoch: 397 Loss: (0.31030776674398763, -0.13520185799302942, -0.12209648396235587)\n",
      "Epoch: 398 Loss: (0.30954917717438113, -0.13451729606461002, -0.12162781685824323)\n",
      "Epoch: 399 Loss: (0.30879489486036504, -0.13383725107042835, -0.12116206366975676)\n",
      "Epoch: 400 Loss: (0.3080448819408766, -0.1331616832155337, -0.12069919950044511)\n"
     ]
    }
   ],
   "source": [
    "# Set limits for 2 axises so that the plot keeps drawing only in a certain space\n",
    "plt.xlim(-15, 8)\n",
    "plt.ylim(-10, 15)\n",
    "\n",
    "plt.plot(x_blue[0][:], x_blue[1][:], 'bo')\n",
    "plt.plot(x_red[0][:], x_red[1][:], 'ro')\n",
    "\n",
    "epoch = 400\n",
    "count_epoch = 1\n",
    "while True:\n",
    "    # Update theta\n",
    "    loss = np.dot(X, (sigmoid(np.dot(theta.T, X)) - Y).T)\n",
    "    theta = theta - alpha*loss\n",
    "    \n",
    "    # Draw a line using theta to see how the algorithm is doing\n",
    "    x_vis = np.array([[-15], [15]])  # vis stand for visualize\n",
    "    y_vis = -(theta[1][0]*x_vis + theta[0][0]) / theta[2][0]\n",
    "    plt.plot(x_vis, y_vis)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "    # Stopping condition\n",
    "    loss = np.dot(X, (sigmoid(np.dot(theta.T, X)) - Y).T)\n",
    "    print(f\"Epoch: {count_epoch} Loss: {loss[0][0], loss[1][0], loss[2][0]}\")\n",
    "    # Check if all values in loss is less than epsilon\n",
    "    # It will probably take a long time to satisfy the above condition, so we will have to use epoch\n",
    "    if (abs(loss) < epsilon).all() or count_epoch == epoch:\n",
    "        break\n",
    "\n",
    "    count_epoch += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Currtent theta after running Losgistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current optimal value of theta_0: -6.321896642589182\n",
      "Current optimal value of theta_1: -2.195838504535509\n",
      "Current optimal value of theta_1: 0.2905439823200238\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current optimal value of theta_0: {theta[0][0]}\")\n",
    "print(f\"Current optimal value of theta_1: {theta[1][0]}\")\n",
    "print(f\"Current optimal value of theta_1: {theta[2][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
