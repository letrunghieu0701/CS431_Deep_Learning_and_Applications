{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 471,
     "status": "ok",
     "timestamp": 1634034658438,
     "user": {
      "displayName": "Hieu Le Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07970718141756542178"
     },
     "user_tz": -420
    },
    "id": "mErhSuJelilO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.linalg import matmul\n",
    "from tensorflow import transpose\n",
    "from tensorflow.math import log\n",
    "from tensorflow.math import reduce_mean\n",
    "from tensorflow.math import minimum\n",
    "from tensorflow.math import maximum\n",
    "from tensorflow.math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe405CFNt7Md"
   },
   "source": [
    "**Create training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634034659134,
     "user": {
      "displayName": "Hieu Le Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07970718141756542178"
     },
     "user_tz": -420
    },
    "id": "c_G8IU38tzQW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (3, 130)\n",
      "Y.shape: (130,)\n"
     ]
    }
   ],
   "source": [
    "n_sample_blue = 80\n",
    "n_sample_red = 50\n",
    "n_sample = n_sample_red + n_sample_blue\n",
    "\n",
    "x_center_blue = np.array([[-6], [9]])\n",
    "x_center_red = np.array([[1], [2]])\n",
    "x_blue = x_center_blue + np.random.normal(0, 2, size=(2, n_sample_blue))\n",
    "x_red = x_center_red + np.random.normal(0, 2, size=(2, n_sample_red))\n",
    "ones = np.ones(n_sample)\n",
    "x = np.hstack((x_blue, x_red))\n",
    "X = np.vstack((ones, x)).astype('float64')\n",
    "\n",
    "Y = np.hstack((np.ones(n_sample_blue), np.zeros(n_sample_red))).astype('float64')\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the below line in Jupyter Notebook to view the plot inside notebook, it doesn't work in Google Colab\n",
    "%matplotlib inline\n",
    "plt.plot(x_blue[0][:], x_blue[1][:], 'bo')\n",
    "plt.plot(x_red[0][:], x_red[1][:], 'ro')\n",
    "# Or\n",
    "# plt.plot(X[1][:n_sample_blue], X[2][:n_sample_blue], 'bo')\n",
    "# plt.plot(X[1][n_sample_blue:], X[2][n_sample_blue:], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldR4yeb7t_2K"
   },
   "source": [
    "**Set value:** theta<br>\n",
    "**Define:** loss function<br>\n",
    "**Note:** Do not define the derivative of the loss function because tensorflow will take the derivative by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function is used to prevent sigmoid returns 1 and 0, these two numbers make a log(0) return infinity value, which makes\n",
    "TensorFlow can not update theta. So we have to set boundaries for sigmoid value.\n",
    "\"\"\"\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + exp(-x))     # Define sigmoid function\n",
    "    sig = minimum(sig, 0.9999999999999999)  # Set upper bound\n",
    "    sig = maximum(sig, 0.0000000000000001)  # Set lower bound\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634034659135,
     "user": {
      "displayName": "Hieu Le Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07970718141756542178"
     },
     "user_tz": -420
    },
    "id": "v--OFsVhuDL7"
   },
   "outputs": [],
   "source": [
    "theta = tf.Variable(np.array([[2.0], [-6.0], [7.0]], dtype=np.float64))\n",
    "epsilon = 0.001\n",
    "\n",
    "# Y_ = sigmoid(matmul(transpose(theta), X))\n",
    "# a = Y * log(Y_) + (1- Y)*log(1 - Y_)\n",
    "# loss = - reduce_mean(a)\n",
    "@tf.function\n",
    "def Loss(theta):\n",
    "    Y_ = sigmoid(matmul(transpose(theta), X))\n",
    "    return - reduce_mean(Y * log(Y_) + (1-Y)*log(1-Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=5.16792357774293>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NadnpZtLuDuI"
   },
   "source": [
    "**Loop:**<br>\n",
    "<span style=\"margin-left:2em\">Update theta</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uJW1PB3FuFg4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 5.38608334   Theta_2_1_0: 6.93311478 -6.01987621 1.97563716\n",
      "Epoch: 2 Loss: 5.33075321   Theta_2_1_0: 6.86689215 -6.03954343 1.95148033\n",
      "Epoch: 3 Loss: 5.27665873   Theta_2_1_0: 6.80109914 -6.05900077 1.92748157\n",
      "Epoch: 4 Loss: 5.22422696   Theta_2_1_0: 6.73532356 -6.07815652 1.90353731\n",
      "Epoch: 5 Loss: 5.17157578   Theta_2_1_0: 6.66980084 -6.09702472 1.87970241\n",
      "Epoch: 6 Loss: 5.11947936   Theta_2_1_0: 6.60448649 -6.11561560 1.85597712\n",
      "Epoch: 7 Loss: 5.06787316   Theta_2_1_0: 6.53941515 -6.13387836 1.83236437\n",
      "Epoch: 8 Loss: 5.01709295   Theta_2_1_0: 6.47444988 -6.15179449 1.80883892\n",
      "Epoch: 9 Loss: 4.95570066   Theta_2_1_0: 6.40530189 -6.16870082 1.78449297\n",
      "Epoch: 10 Loss: 4.90225865   Theta_2_1_0: 6.33452429 -6.18522305 1.75992713\n",
      "Epoch: 11 Loss: 4.84302707   Theta_2_1_0: 6.26469292 -6.20096180 1.73555553\n",
      "Epoch: 12 Loss: 4.78723170   Theta_2_1_0: 6.19448726 -6.21597412 1.71113922\n",
      "Epoch: 13 Loss: 4.73257124   Theta_2_1_0: 6.12322798 -6.23023154 1.68654404\n",
      "Epoch: 14 Loss: 4.66470579   Theta_2_1_0: 6.05227564 -6.24416726 1.66211675\n",
      "Epoch: 15 Loss: 4.60979414   Theta_2_1_0: 5.98013051 -6.25719339 1.63745491\n",
      "Epoch: 16 Loss: 4.55004671   Theta_2_1_0: 5.90827636 -6.26980363 1.61292016\n",
      "Epoch: 17 Loss: 4.49478691   Theta_2_1_0: 5.83507075 -6.28127171 1.58807600\n",
      "Epoch: 18 Loss: 4.43114907   Theta_2_1_0: 5.76369228 -6.29311453 1.56375858\n",
      "Epoch: 19 Loss: 4.37492617   Theta_2_1_0: 5.69184300 -6.30420393 1.53936194\n",
      "Epoch: 20 Loss: 4.31610945   Theta_2_1_0: 5.62065273 -6.31501953 1.51517280\n",
      "Epoch: 21 Loss: 4.25822609   Theta_2_1_0: 5.55007825 -6.32554306 1.49118828\n",
      "Epoch: 22 Loss: 4.20222808   Theta_2_1_0: 5.47979528 -6.33554247 1.46731300\n",
      "Epoch: 23 Loss: 4.14105524   Theta_2_1_0: 5.40807250 -6.34458162 1.44320479\n",
      "Epoch: 24 Loss: 4.08380593   Theta_2_1_0: 5.33629406 -6.35314010 1.41917192\n",
      "Epoch: 25 Loss: 4.02822962   Theta_2_1_0: 5.26358605 -6.36090334 1.39500371\n",
      "Epoch: 26 Loss: 3.96712311   Theta_2_1_0: 5.19230335 -6.36853921 1.37117551\n",
      "Epoch: 27 Loss: 3.91244642   Theta_2_1_0: 5.12001793 -6.37551311 1.34720067\n",
      "Epoch: 28 Loss: 3.85430964   Theta_2_1_0: 5.04811718 -6.38226382 1.32336329\n",
      "Epoch: 29 Loss: 3.79561300   Theta_2_1_0: 4.97707899 -6.38898857 1.29976517\n",
      "Epoch: 30 Loss: 3.73943847   Theta_2_1_0: 4.90607657 -6.39548071 1.27623008\n",
      "Epoch: 31 Loss: 3.68317268   Theta_2_1_0: 4.83521616 -6.40181397 1.25278451\n",
      "Epoch: 32 Loss: 3.62737052   Theta_2_1_0: 4.76439657 -6.40797596 1.22940760\n",
      "Epoch: 33 Loss: 3.57120128   Theta_2_1_0: 4.69388607 -6.41405217 1.20615583\n",
      "Epoch: 34 Loss: 3.51580237   Theta_2_1_0: 4.62349413 -6.41999659 1.18299122\n",
      "Epoch: 35 Loss: 3.46060745   Theta_2_1_0: 4.55324292 -6.42581620 1.15991985\n",
      "Epoch: 36 Loss: 3.40564465   Theta_2_1_0: 4.48315831 -6.43151206 1.13694781\n",
      "Epoch: 37 Loss: 3.35102631   Theta_2_1_0: 4.41322837 -6.43707042 1.11407325\n",
      "Epoch: 38 Loss: 3.29129515   Theta_2_1_0: 4.34210658 -6.44121399 1.09090301\n",
      "Epoch: 39 Loss: 3.23628486   Theta_2_1_0: 4.27077671 -6.44483980 1.06772579\n",
      "Epoch: 40 Loss: 3.18135502   Theta_2_1_0: 4.19912671 -6.44782286 1.04451005\n",
      "Epoch: 41 Loss: 3.12636914   Theta_2_1_0: 4.12704209 -6.45000917 1.02122046\n",
      "Epoch: 42 Loss: 3.07135993   Theta_2_1_0: 4.05430871 -6.45117811 0.99779626\n",
      "Epoch: 43 Loss: 3.01080138   Theta_2_1_0: 3.98321154 -6.45340347 0.97490341\n",
      "Epoch: 44 Loss: 2.95389863   Theta_2_1_0: 3.91277026 -6.45574768 0.95225561\n",
      "Epoch: 45 Loss: 2.90088357   Theta_2_1_0: 3.84201296 -6.45728046 0.92956918\n",
      "Epoch: 46 Loss: 2.84573858   Theta_2_1_0: 3.77168878 -6.45866087 0.90706234\n",
      "Epoch: 47 Loss: 2.79172886   Theta_2_1_0: 3.70163914 -6.45971382 0.88468848\n",
      "Epoch: 48 Loss: 2.73738741   Theta_2_1_0: 3.63219989 -6.46072284 0.86254516\n",
      "Epoch: 49 Loss: 2.68448111   Theta_2_1_0: 3.56316435 -6.46146928 0.84057142\n",
      "Epoch: 50 Loss: 2.63194640   Theta_2_1_0: 3.49465296 -6.46203617 0.81880177\n",
      "Epoch: 51 Loss: 2.58065579   Theta_2_1_0: 3.42652338 -6.46226157 0.79719405\n",
      "Epoch: 52 Loss: 2.52953068   Theta_2_1_0: 3.35897407 -6.46229482 0.77580556\n",
      "Epoch: 53 Loss: 2.47971665   Theta_2_1_0: 3.29186837 -6.46197265 0.75459579\n",
      "Epoch: 54 Loss: 2.43021809   Theta_2_1_0: 3.22538352 -6.46141845 0.73361594\n",
      "Epoch: 55 Loss: 2.38187241   Theta_2_1_0: 3.15946031 -6.46053639 0.71284823\n",
      "Epoch: 56 Loss: 2.33429533   Theta_2_1_0: 3.09416048 -6.45934275 0.69231026\n",
      "Epoch: 57 Loss: 2.28766679   Theta_2_1_0: 3.02950133 -6.45781606 0.67200668\n",
      "Epoch: 58 Loss: 2.24197372   Theta_2_1_0: 2.96550761 -6.45594724 0.65194435\n",
      "Epoch: 59 Loss: 2.19717013   Theta_2_1_0: 2.90222160 -6.45375120 0.63213523\n",
      "Epoch: 60 Loss: 2.15339409   Theta_2_1_0: 2.83964131 -6.45121125 0.61257828\n",
      "Epoch: 61 Loss: 2.11060015   Theta_2_1_0: 2.77777021 -6.44832569 0.59327401\n",
      "Epoch: 62 Loss: 2.06874293   Theta_2_1_0: 2.71661663 -6.44510747 0.57422420\n",
      "Epoch: 63 Loss: 2.02784265   Theta_2_1_0: 2.65617090 -6.44156289 0.55542525\n",
      "Epoch: 64 Loss: 1.98787610   Theta_2_1_0: 2.59641523 -6.43769980 0.53687106\n",
      "Epoch: 65 Loss: 1.94880393   Theta_2_1_0: 2.53732698 -6.43352958 0.51855398\n",
      "Epoch: 66 Loss: 1.91056929   Theta_2_1_0: 2.47888384 -6.42907053 0.50046635\n",
      "Epoch: 67 Loss: 1.87313794   Theta_2_1_0: 2.42105674 -6.42433988 0.48259847\n",
      "Epoch: 68 Loss: 1.83646231   Theta_2_1_0: 2.36381401 -6.41935592 0.46493983\n",
      "Epoch: 69 Loss: 1.80049983   Theta_2_1_0: 2.30712042 -6.41413544 0.44747887\n",
      "Epoch: 70 Loss: 1.76519384   Theta_2_1_0: 2.25094287 -6.40869738 0.43020470\n",
      "Epoch: 71 Loss: 1.73049898   Theta_2_1_0: 2.19524869 -6.40305977 0.41310661\n",
      "Epoch: 72 Loss: 1.69637691   Theta_2_1_0: 2.14000513 -6.39723791 0.39617394\n",
      "Epoch: 73 Loss: 1.66277801   Theta_2_1_0: 2.08518485 -6.39124842 0.37939773\n",
      "Epoch: 74 Loss: 1.62967114   Theta_2_1_0: 2.03076250 -6.38510514 0.36276969\n",
      "Epoch: 75 Loss: 1.59702087   Theta_2_1_0: 1.97671816 -6.37882166 0.34628321\n",
      "Epoch: 76 Loss: 1.56480514   Theta_2_1_0: 1.92303536 -6.37240895 0.32993277\n",
      "Epoch: 77 Loss: 1.53300411   Theta_2_1_0: 1.86970242 -6.36587628 0.31371428\n",
      "Epoch: 78 Loss: 1.50160127   Theta_2_1_0: 1.81671367 -6.35923201 0.29762542\n",
      "Epoch: 79 Loss: 1.47059113   Theta_2_1_0: 1.76406816 -6.35248218 0.28166517\n",
      "Epoch: 80 Loss: 1.43997063   Theta_2_1_0: 1.71177108 -6.34563162 0.26583419\n",
      "Epoch: 81 Loss: 1.40974550   Theta_2_1_0: 1.65983322 -6.33868324 0.25013456\n",
      "Epoch: 82 Loss: 1.37992620   Theta_2_1_0: 1.60827168 -6.33163858 0.23456993\n",
      "Epoch: 83 Loss: 1.35053075   Theta_2_1_0: 1.55710962 -6.32449744 0.21914538\n",
      "Epoch: 84 Loss: 1.32158187   Theta_2_1_0: 1.50637676 -6.31725844 0.20386745\n",
      "Epoch: 85 Loss: 1.29310975   Theta_2_1_0: 1.45610873 -6.30991868 0.18874398\n",
      "Epoch: 86 Loss: 1.26514864   Theta_2_1_0: 1.40634687 -6.30247431 0.17378398\n",
      "Epoch: 87 Loss: 1.23773795   Theta_2_1_0: 1.35713717 -6.29492050 0.15899733\n",
      "Epoch: 88 Loss: 1.21091973   Theta_2_1_0: 1.30852903 -6.28725188 0.14439452\n",
      "Epoch: 89 Loss: 1.18473737   Theta_2_1_0: 1.26057364 -6.27946287 0.12998625\n",
      "Epoch: 90 Loss: 1.15923359   Theta_2_1_0: 1.21332232 -6.27154807 0.11578300\n",
      "Epoch: 91 Loss: 1.13444865   Theta_2_1_0: 1.16682470 -6.26350249 0.10179467\n",
      "Epoch: 92 Loss: 1.11041825   Theta_2_1_0: 1.12112759 -6.25532197 0.08803026\n",
      "Epoch: 93 Loss: 1.08717292   Theta_2_1_0: 1.07627378 -6.24700321 0.07449764\n",
      "Epoch: 94 Loss: 1.06473682   Theta_2_1_0: 1.03230144 -6.23854390 0.06120336\n",
      "Epoch: 95 Loss: 1.04312754   Theta_2_1_0: 0.98924361 -6.22994269 0.04815261\n",
      "Epoch: 96 Loss: 1.02235583   Theta_2_1_0: 0.94712773 -6.22119923 0.03534906\n",
      "Epoch: 97 Loss: 1.00242567   Theta_2_1_0: 0.90597495 -6.21231409 0.02279482\n",
      "Epoch: 98 Loss: 0.98333391   Theta_2_1_0: 0.86579940 -6.20328880 0.01049036\n",
      "Epoch: 99 Loss: 0.96507031   Theta_2_1_0: 0.82660733 -6.19412585 -0.00156561\n",
      "Epoch: 100 Loss: 0.94761732   Theta_2_1_0: 0.78839632 -6.18482872 -0.01337618\n",
      "Epoch: 101 Loss: 0.93095033   Theta_2_1_0: 0.75115484 -6.17540184 -0.02494622\n",
      "Epoch: 102 Loss: 0.91503808   Theta_2_1_0: 0.71486226 -6.16585059 -0.03628234\n",
      "Epoch: 103 Loss: 0.89984354   Theta_2_1_0: 0.67948946 -6.15618111 -0.04739263\n",
      "Epoch: 104 Loss: 0.88532517   Theta_2_1_0: 0.64499999 -6.14640021 -0.05828647\n",
      "Epoch: 105 Loss: 0.87143837   Theta_2_1_0: 0.61135162 -6.13651513 -0.06897414\n",
      "Epoch: 106 Loss: 0.85813700   Theta_2_1_0: 0.57849810 -6.12653335 -0.07946655\n",
      "Epoch: 107 Loss: 0.84537487   Theta_2_1_0: 0.54639088 -6.11646238 -0.08977486\n",
      "Epoch: 108 Loss: 0.83310687   Theta_2_1_0: 0.51498065 -6.10630962 -0.09991022\n",
      "Epoch: 109 Loss: 0.82128992   Theta_2_1_0: 0.48421861 -6.09608218 -0.10988353\n",
      "Epoch: 110 Loss: 0.80988360   Theta_2_1_0: 0.45405745 -6.08578684 -0.11970532\n",
      "Epoch: 111 Loss: 0.79885046   Theta_2_1_0: 0.42445203 -6.07542995 -0.12938555\n",
      "Epoch: 112 Loss: 0.78815621   Theta_2_1_0: 0.39535982 -6.06501742 -0.13893362\n",
      "Epoch: 113 Loss: 0.77776968   Theta_2_1_0: 0.36674117 -6.05455471 -0.14835826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114 Loss: 0.76766276   Theta_2_1_0: 0.33855940 -6.04404683 -0.15766757\n",
      "Epoch: 115 Loss: 0.75781017   Theta_2_1_0: 0.31078082 -6.03349837 -0.16686899\n",
      "Epoch: 116 Loss: 0.74818933   Theta_2_1_0: 0.28337464 -6.02291352 -0.17596934\n",
      "Epoch: 117 Loss: 0.73878009   Theta_2_1_0: 0.25631290 -6.01229607 -0.18497483\n",
      "Epoch: 118 Loss: 0.72956453   Theta_2_1_0: 0.22957026 -6.00164949 -0.19389110\n",
      "Epoch: 119 Loss: 0.72052674   Theta_2_1_0: 0.20312389 -5.99097691 -0.20272326\n",
      "Epoch: 120 Loss: 0.71165262   Theta_2_1_0: 0.17695326 -5.98028118 -0.21147595\n",
      "Epoch: 121 Loss: 0.70292971   Theta_2_1_0: 0.15103994 -5.96956489 -0.22015333\n",
      "Epoch: 122 Loss: 0.69434697   Theta_2_1_0: 0.12536746 -5.95883037 -0.22875915\n",
      "Epoch: 123 Loss: 0.68589466   Theta_2_1_0: 0.09992112 -5.94807977 -0.23729681\n",
      "Epoch: 124 Loss: 0.67756417   Theta_2_1_0: 0.07468778 -5.93731501 -0.24576936\n",
      "Epoch: 125 Loss: 0.66934789   Theta_2_1_0: 0.04965577 -5.92653788 -0.25417955\n",
      "Epoch: 126 Loss: 0.66123910   Theta_2_1_0: 0.02481471 -5.91574998 -0.26252987\n",
      "Epoch: 127 Loss: 0.65323188   Theta_2_1_0: 0.00015537 -5.90495281 -0.27082257\n",
      "Epoch: 128 Loss: 0.64532099   Theta_2_1_0: -0.02433040 -5.89414775 -0.27905970\n",
      "Epoch: 129 Loss: 0.63750179   Theta_2_1_0: -0.04864982 -5.88333607 -0.28724310\n",
      "Epoch: 130 Loss: 0.62977024   Theta_2_1_0: -0.07280920 -5.87251898 -0.29537446\n",
      "Epoch: 131 Loss: 0.62212277   Theta_2_1_0: -0.09681402 -5.86169762 -0.30345532\n",
      "Epoch: 132 Loss: 0.61455630   Theta_2_1_0: -0.12066898 -5.85087308 -0.31148708\n",
      "Epoch: 133 Loss: 0.60706817   Theta_2_1_0: -0.14437797 -5.84004644 -0.31947100\n",
      "Epoch: 134 Loss: 0.59965620   Theta_2_1_0: -0.16794407 -5.82921876 -0.32740822\n",
      "Epoch: 135 Loss: 0.59231861   Theta_2_1_0: -0.19136951 -5.81839111 -0.33529974\n",
      "Epoch: 136 Loss: 0.58505411   Theta_2_1_0: -0.21465557 -5.80756463 -0.34314644\n",
      "Epoch: 137 Loss: 0.57786189   Theta_2_1_0: -0.23780247 -5.79674050 -0.35094906\n",
      "Epoch: 138 Loss: 0.57074174   Theta_2_1_0: -0.26080919 -5.78592002 -0.35870817\n",
      "Epoch: 139 Loss: 0.56369404   Theta_2_1_0: -0.28367326 -5.77510461 -0.36642418\n",
      "Epoch: 140 Loss: 0.55671997   Theta_2_1_0: -0.30639043 -5.76429593 -0.37409728\n",
      "Epoch: 141 Loss: 0.54982156   Theta_2_1_0: -0.32895438 -5.75349583 -0.38172745\n",
      "Epoch: 142 Loss: 0.54300191   Theta_2_1_0: -0.35135618 -5.74270653 -0.38931438\n",
      "Epoch: 143 Loss: 0.53626538   Theta_2_1_0: -0.37358380 -5.73193062 -0.39685743\n",
      "Epoch: 144 Loss: 0.52961783   Theta_2_1_0: -0.39562143 -5.72117120 -0.40435559\n",
      "Epoch: 145 Loss: 0.52306688   Theta_2_1_0: -0.41744872 -5.71043200 -0.41180738\n",
      "Epoch: 146 Loss: 0.51662224   Theta_2_1_0: -0.43903997 -5.69971745 -0.41921082\n",
      "Epoch: 147 Loss: 0.51029596   Theta_2_1_0: -0.46036316 -5.68903286 -0.42656333\n",
      "Epoch: 148 Loss: 0.50410273   Theta_2_1_0: -0.48137919 -5.67838453 -0.43386167\n",
      "Epoch: 149 Loss: 0.49806003   Theta_2_1_0: -0.50204110 -5.66777985 -0.44110186\n",
      "Epoch: 150 Loss: 0.49218815   Theta_2_1_0: -0.52229369 -5.65722736 -0.44827921\n",
      "Epoch: 151 Loss: 0.48650992   Theta_2_1_0: -0.54207367 -5.64673673 -0.45538831\n",
      "Epoch: 152 Loss: 0.48105008   Theta_2_1_0: -0.56131060 -5.63631866 -0.46242317\n",
      "Epoch: 153 Loss: 0.47583427   Theta_2_1_0: -0.57992877 -5.62598456 -0.46937737\n",
      "Epoch: 154 Loss: 0.47088745   Theta_2_1_0: -0.59785025 -5.61574618 -0.47624440\n",
      "Epoch: 155 Loss: 0.46623208   Theta_2_1_0: -0.61499886 -5.60561502 -0.48301802\n",
      "Epoch: 156 Loss: 0.46188605   Theta_2_1_0: -0.63130481 -5.59560167 -0.48969268\n",
      "Epoch: 157 Loss: 0.45786085   Theta_2_1_0: -0.64670936 -5.58571514 -0.49626397\n",
      "Epoch: 158 Loss: 0.45416023   Theta_2_1_0: -0.66116879 -5.57596230 -0.50272891\n",
      "Epoch: 159 Loss: 0.45077973   Theta_2_1_0: -0.67465704 -5.56634747 -0.50908622\n",
      "Epoch: 160 Loss: 0.44770712   Theta_2_1_0: -0.68716661 -5.55687229 -0.51533637\n",
      "Epoch: 161 Loss: 0.44492364   Theta_2_1_0: -0.69870774 -5.54753585 -0.52148143\n",
      "Epoch: 162 Loss: 0.44240579   Theta_2_1_0: -0.70930615 -5.53833495 -0.52752486\n",
      "Epoch: 163 Loss: 0.44012734   Theta_2_1_0: -0.71899990 -5.52926457 -0.53347122\n",
      "Epoch: 164 Loss: 0.43806111   Theta_2_1_0: -0.72783595 -5.52031838 -0.53932582\n",
      "Epoch: 165 Loss: 0.43618047   Theta_2_1_0: -0.73586685 -5.51148916 -0.54509439\n",
      "Epoch: 166 Loss: 0.43446041   Theta_2_1_0: -0.74314787 -5.50276926 -0.55078286\n",
      "Epoch: 167 Loss: 0.43287812   Theta_2_1_0: -0.74973469 -5.49415091 -0.55639711\n",
      "Epoch: 168 Loss: 0.43141335   Theta_2_1_0: -0.75568179 -5.48562649 -0.56194285\n",
      "Epoch: 169 Loss: 0.43004839   Theta_2_1_0: -0.76104123 -5.47718866 -0.56742550\n",
      "Epoch: 170 Loss: 0.42876800   Theta_2_1_0: -0.76586198 -5.46883049 -0.57285013\n",
      "Epoch: 171 Loss: 0.42755916   Theta_2_1_0: -0.77018955 -5.46054554 -0.57822145\n",
      "Epoch: 172 Loss: 0.42641085   Theta_2_1_0: -0.77406587 -5.45232784 -0.58354378\n",
      "Epoch: 173 Loss: 0.42531377   Theta_2_1_0: -0.77752932 -5.44417192 -0.58882110\n",
      "Epoch: 174 Loss: 0.42426009   Theta_2_1_0: -0.78061488 -5.43607278 -0.59405701\n",
      "Epoch: 175 Loss: 0.42324324   Theta_2_1_0: -0.78335434 -5.42802586 -0.59925479\n",
      "Epoch: 176 Loss: 0.42225770   Theta_2_1_0: -0.78577654 -5.42002701 -0.60441743\n",
      "Epoch: 177 Loss: 0.42129883   Theta_2_1_0: -0.78790761 -5.41207247 -0.60954764\n",
      "Epoch: 178 Loss: 0.42036273   Theta_2_1_0: -0.78977125 -5.40415882 -0.61464786\n",
      "Epoch: 179 Loss: 0.41944612   Theta_2_1_0: -0.79138892 -5.39628296 -0.61972033\n",
      "Epoch: 180 Loss: 0.41854622   Theta_2_1_0: -0.79278009 -5.38844207 -0.62476709\n",
      "Epoch: 181 Loss: 0.41766070   Theta_2_1_0: -0.79396244 -5.38063357 -0.62978996\n",
      "Epoch: 182 Loss: 0.41678758   Theta_2_1_0: -0.79495203 -5.37285513 -0.63479064\n",
      "Epoch: 183 Loss: 0.41592516   Theta_2_1_0: -0.79576349 -5.36510463 -0.63977065\n",
      "Epoch: 184 Loss: 0.41507203   Theta_2_1_0: -0.79641014 -5.35738010 -0.64473140\n",
      "Epoch: 185 Loss: 0.41422695   Theta_2_1_0: -0.79690414 -5.34967977 -0.64967415\n",
      "Epoch: 186 Loss: 0.41338889   Theta_2_1_0: -0.79725659 -5.34200202 -0.65460009\n",
      "Epoch: 187 Loss: 0.41255694   Theta_2_1_0: -0.79747768 -5.33434535 -0.65951029\n",
      "Epoch: 188 Loss: 0.41173036   Theta_2_1_0: -0.79757672 -5.32670839 -0.66440574\n",
      "Epoch: 189 Loss: 0.41090848   Theta_2_1_0: -0.79756227 -5.31908988 -0.66928734\n",
      "Epoch: 190 Loss: 0.41009073   Theta_2_1_0: -0.79744220 -5.31148865 -0.67415593\n",
      "Epoch: 191 Loss: 0.40927662   Theta_2_1_0: -0.79722376 -5.30390365 -0.67901227\n",
      "Epoch: 192 Loss: 0.40846574   Theta_2_1_0: -0.79691361 -5.29633387 -0.68385710\n",
      "Epoch: 193 Loss: 0.40765771   Theta_2_1_0: -0.79651793 -5.28877841 -0.68869105\n",
      "Epoch: 194 Loss: 0.40685222   Theta_2_1_0: -0.79604240 -5.28123643 -0.69351474\n",
      "Epoch: 195 Loss: 0.40604900   Theta_2_1_0: -0.79549230 -5.27370714 -0.69832873\n",
      "Epoch: 196 Loss: 0.40524781   Theta_2_1_0: -0.79487251 -5.26618982 -0.70313355\n",
      "Epoch: 197 Loss: 0.40444843   Theta_2_1_0: -0.79418754 -5.25868379 -0.70792968\n",
      "Epoch: 198 Loss: 0.40365070   Theta_2_1_0: -0.79344161 -5.25118844 -0.71271758\n",
      "Epoch: 199 Loss: 0.40285444   Theta_2_1_0: -0.79263860 -5.24370318 -0.71749765\n",
      "Epoch: 200 Loss: 0.40205953   Theta_2_1_0: -0.79178216 -5.23622746 -0.72227030\n",
      "Epoch: 201 Loss: 0.40126584   Theta_2_1_0: -0.79087566 -5.22876080 -0.72703589\n",
      "Epoch: 202 Loss: 0.40047328   Theta_2_1_0: -0.78992224 -5.22130271 -0.73179474\n",
      "Epoch: 203 Loss: 0.39968173   Theta_2_1_0: -0.78892484 -5.21385277 -0.73654719\n",
      "Epoch: 204 Loss: 0.39889114   Theta_2_1_0: -0.78788619 -5.20641057 -0.74129353\n",
      "Epoch: 205 Loss: 0.39810142   Theta_2_1_0: -0.78680886 -5.19897572 -0.74603402\n",
      "Epoch: 206 Loss: 0.39731252   Theta_2_1_0: -0.78569521 -5.19154787 -0.75076893\n",
      "Epoch: 207 Loss: 0.39652438   Theta_2_1_0: -0.78454750 -5.18412669 -0.75549850\n",
      "Epoch: 208 Loss: 0.39573695   Theta_2_1_0: -0.78336779 -5.17671187 -0.76022295\n",
      "Epoch: 209 Loss: 0.39495020   Theta_2_1_0: -0.78215805 -5.16930312 -0.76494249\n",
      "Epoch: 210 Loss: 0.39416408   Theta_2_1_0: -0.78092010 -5.16190018 -0.76965732\n",
      "Epoch: 211 Loss: 0.39337857   Theta_2_1_0: -0.77965565 -5.15450278 -0.77436761\n",
      "Epoch: 212 Loss: 0.39259364   Theta_2_1_0: -0.77836630 -5.14711069 -0.77907355\n",
      "Epoch: 213 Loss: 0.39180927   Theta_2_1_0: -0.77705357 -5.13972369 -0.78377529\n",
      "Epoch: 214 Loss: 0.39102542   Theta_2_1_0: -0.77571885 -5.13234157 -0.78847298\n",
      "Epoch: 215 Loss: 0.39024210   Theta_2_1_0: -0.77436347 -5.12496414 -0.79316677\n",
      "Epoch: 216 Loss: 0.38945927   Theta_2_1_0: -0.77298868 -5.11759121 -0.79785678\n",
      "Epoch: 217 Loss: 0.38867692   Theta_2_1_0: -0.77159563 -5.11022262 -0.80254314\n",
      "Epoch: 218 Loss: 0.38789506   Theta_2_1_0: -0.77018541 -5.10285821 -0.80722596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219 Loss: 0.38711365   Theta_2_1_0: -0.76875907 -5.09549783 -0.81190536\n",
      "Epoch: 220 Loss: 0.38633270   Theta_2_1_0: -0.76731755 -5.08814134 -0.81658142\n",
      "Epoch: 221 Loss: 0.38555219   Theta_2_1_0: -0.76586177 -5.08078861 -0.82125426\n",
      "Epoch: 222 Loss: 0.38477213   Theta_2_1_0: -0.76439258 -5.07343952 -0.82592395\n",
      "Epoch: 223 Loss: 0.38399250   Theta_2_1_0: -0.76291077 -5.06609395 -0.83059059\n",
      "Epoch: 224 Loss: 0.38321330   Theta_2_1_0: -0.76141711 -5.05875180 -0.83525424\n",
      "Epoch: 225 Loss: 0.38243453   Theta_2_1_0: -0.75991229 -5.05141297 -0.83991498\n",
      "Epoch: 226 Loss: 0.38165618   Theta_2_1_0: -0.75839698 -5.04407736 -0.84457287\n",
      "Epoch: 227 Loss: 0.38087825   Theta_2_1_0: -0.75687181 -5.03674490 -0.84922799\n",
      "Epoch: 228 Loss: 0.38010075   Theta_2_1_0: -0.75533736 -5.02941549 -0.85388039\n",
      "Epoch: 229 Loss: 0.37932365   Theta_2_1_0: -0.75379419 -5.02208907 -0.85853012\n",
      "Epoch: 230 Loss: 0.37854698   Theta_2_1_0: -0.75224282 -5.01476556 -0.86317724\n",
      "Epoch: 231 Loss: 0.37777072   Theta_2_1_0: -0.75068374 -5.00744490 -0.86782180\n",
      "Epoch: 232 Loss: 0.37699488   Theta_2_1_0: -0.74911740 -5.00012703 -0.87246383\n",
      "Epoch: 233 Loss: 0.37621945   Theta_2_1_0: -0.74754424 -4.99281189 -0.87710339\n",
      "Epoch: 234 Loss: 0.37544444   Theta_2_1_0: -0.74596467 -4.98549943 -0.88174050\n",
      "Epoch: 235 Loss: 0.37466984   Theta_2_1_0: -0.74437907 -4.97818960 -0.88637521\n",
      "Epoch: 236 Loss: 0.37389567   Theta_2_1_0: -0.74278779 -4.97088236 -0.89100756\n",
      "Epoch: 237 Loss: 0.37312190   Theta_2_1_0: -0.74119119 -4.96357766 -0.89563756\n",
      "Epoch: 238 Loss: 0.37234856   Theta_2_1_0: -0.73958958 -4.95627547 -0.90026525\n",
      "Epoch: 239 Loss: 0.37157564   Theta_2_1_0: -0.73798326 -4.94897574 -0.90489066\n",
      "Epoch: 240 Loss: 0.37080314   Theta_2_1_0: -0.73637250 -4.94167846 -0.90951380\n",
      "Epoch: 241 Loss: 0.37003106   Theta_2_1_0: -0.73475759 -4.93438358 -0.91413472\n",
      "Epoch: 242 Loss: 0.36925941   Theta_2_1_0: -0.73313876 -4.92709109 -0.91875341\n",
      "Epoch: 243 Loss: 0.36848818   Theta_2_1_0: -0.73151625 -4.91980095 -0.92336991\n",
      "Epoch: 244 Loss: 0.36771738   Theta_2_1_0: -0.72989028 -4.91251314 -0.92798423\n",
      "Epoch: 245 Loss: 0.36694701   Theta_2_1_0: -0.72826107 -4.90522764 -0.93259638\n",
      "Epoch: 246 Loss: 0.36617707   Theta_2_1_0: -0.72662880 -4.89794445 -0.93720639\n",
      "Epoch: 247 Loss: 0.36540757   Theta_2_1_0: -0.72499367 -4.89066352 -0.94181426\n",
      "Epoch: 248 Loss: 0.36463849   Theta_2_1_0: -0.72335584 -4.88338486 -0.94642000\n",
      "Epoch: 249 Loss: 0.36386986   Theta_2_1_0: -0.72171547 -4.87610845 -0.95102364\n",
      "Epoch: 250 Loss: 0.36310167   Theta_2_1_0: -0.72007273 -4.86883428 -0.95562517\n",
      "Epoch: 251 Loss: 0.36233392   Theta_2_1_0: -0.71842776 -4.86156234 -0.96022460\n",
      "Epoch: 252 Loss: 0.36156661   Theta_2_1_0: -0.71678068 -4.85429261 -0.96482195\n",
      "Epoch: 253 Loss: 0.36079975   Theta_2_1_0: -0.71513163 -4.84702510 -0.96941721\n",
      "Epoch: 254 Loss: 0.36003333   Theta_2_1_0: -0.71348073 -4.83975980 -0.97401040\n",
      "Epoch: 255 Loss: 0.35926737   Theta_2_1_0: -0.71182809 -4.83249669 -0.97860152\n",
      "Epoch: 256 Loss: 0.35850186   Theta_2_1_0: -0.71017382 -4.82523578 -0.98319057\n",
      "Epoch: 257 Loss: 0.35773681   Theta_2_1_0: -0.70851801 -4.81797707 -0.98777756\n",
      "Epoch: 258 Loss: 0.35697221   Theta_2_1_0: -0.70686076 -4.81072055 -0.99236249\n",
      "Epoch: 259 Loss: 0.35620808   Theta_2_1_0: -0.70520217 -4.80346623 -0.99694536\n",
      "Epoch: 260 Loss: 0.35544441   Theta_2_1_0: -0.70354230 -4.79621409 -1.00152617\n",
      "Epoch: 261 Loss: 0.35468120   Theta_2_1_0: -0.70188125 -4.78896416 -1.00610492\n",
      "Epoch: 262 Loss: 0.35391846   Theta_2_1_0: -0.70021907 -4.78171641 -1.01068161\n",
      "Epoch: 263 Loss: 0.35315619   Theta_2_1_0: -0.69855585 -4.77447087 -1.01525625\n",
      "Epoch: 264 Loss: 0.35239439   Theta_2_1_0: -0.69689165 -4.76722753 -1.01982882\n",
      "Epoch: 265 Loss: 0.35163307   Theta_2_1_0: -0.69522653 -4.75998639 -1.02439934\n",
      "Epoch: 266 Loss: 0.35087223   Theta_2_1_0: -0.69356054 -4.75274747 -1.02896779\n",
      "Epoch: 267 Loss: 0.35011187   Theta_2_1_0: -0.69189374 -4.74551077 -1.03353417\n",
      "Epoch: 268 Loss: 0.34935199   Theta_2_1_0: -0.69022618 -4.73827628 -1.03809849\n",
      "Epoch: 269 Loss: 0.34859260   Theta_2_1_0: -0.68855791 -4.73104403 -1.04266073\n",
      "Epoch: 270 Loss: 0.34783369   Theta_2_1_0: -0.68688897 -4.72381401 -1.04722089\n",
      "Epoch: 271 Loss: 0.34707528   Theta_2_1_0: -0.68521941 -4.71658624 -1.05177898\n",
      "Epoch: 272 Loss: 0.34631736   Theta_2_1_0: -0.68354926 -4.70936072 -1.05633498\n",
      "Epoch: 273 Loss: 0.34555994   Theta_2_1_0: -0.68187856 -4.70213746 -1.06088889\n",
      "Epoch: 274 Loss: 0.34480301   Theta_2_1_0: -0.68020735 -4.69491647 -1.06544071\n",
      "Epoch: 275 Loss: 0.34404659   Theta_2_1_0: -0.67853566 -4.68769776 -1.06999042\n",
      "Epoch: 276 Loss: 0.34329068   Theta_2_1_0: -0.67686352 -4.68048134 -1.07453803\n",
      "Epoch: 277 Loss: 0.34253527   Theta_2_1_0: -0.67519097 -4.67326722 -1.07908353\n",
      "Epoch: 278 Loss: 0.34178037   Theta_2_1_0: -0.67351802 -4.66605541 -1.08362691\n",
      "Epoch: 279 Loss: 0.34102599   Theta_2_1_0: -0.67184471 -4.65884592 -1.08816817\n",
      "Epoch: 280 Loss: 0.34027212   Theta_2_1_0: -0.67017105 -4.65163876 -1.09270730\n",
      "Epoch: 281 Loss: 0.33951877   Theta_2_1_0: -0.66849708 -4.64443394 -1.09724428\n",
      "Epoch: 282 Loss: 0.33876595   Theta_2_1_0: -0.66682282 -4.63723149 -1.10177912\n",
      "Epoch: 283 Loss: 0.33801364   Theta_2_1_0: -0.66514827 -4.63003139 -1.10631181\n",
      "Epoch: 284 Loss: 0.33726187   Theta_2_1_0: -0.66347347 -4.62283368 -1.11084235\n",
      "Epoch: 285 Loss: 0.33651062   Theta_2_1_0: -0.66179844 -4.61563836 -1.11537071\n",
      "Epoch: 286 Loss: 0.33575991   Theta_2_1_0: -0.66012318 -4.60844545 -1.11989689\n",
      "Epoch: 287 Loss: 0.33500974   Theta_2_1_0: -0.65844772 -4.60125496 -1.12442090\n",
      "Epoch: 288 Loss: 0.33426011   Theta_2_1_0: -0.65677207 -4.59406689 -1.12894271\n",
      "Epoch: 289 Loss: 0.33351101   Theta_2_1_0: -0.65509624 -4.58688128 -1.13346232\n",
      "Epoch: 290 Loss: 0.33276247   Theta_2_1_0: -0.65342026 -4.57969812 -1.13797973\n",
      "Epoch: 291 Loss: 0.33201447   Theta_2_1_0: -0.65174412 -4.57251744 -1.14249491\n",
      "Epoch: 292 Loss: 0.33126702   Theta_2_1_0: -0.65006785 -4.56533924 -1.14700788\n",
      "Epoch: 293 Loss: 0.33052013   Theta_2_1_0: -0.64839146 -4.55816355 -1.15151860\n",
      "Epoch: 294 Loss: 0.32977379   Theta_2_1_0: -0.64671496 -4.55099037 -1.15602709\n",
      "Epoch: 295 Loss: 0.32902802   Theta_2_1_0: -0.64503835 -4.54381972 -1.16053331\n",
      "Epoch: 296 Loss: 0.32828281   Theta_2_1_0: -0.64336165 -4.53665162 -1.16503728\n",
      "Epoch: 297 Loss: 0.32753816   Theta_2_1_0: -0.64168487 -4.52948609 -1.16953898\n",
      "Epoch: 298 Loss: 0.32679409   Theta_2_1_0: -0.64000802 -4.52232313 -1.17403839\n",
      "Epoch: 299 Loss: 0.32605058   Theta_2_1_0: -0.63833110 -4.51516276 -1.17853552\n",
      "Epoch: 300 Loss: 0.32530766   Theta_2_1_0: -0.63665413 -4.50800500 -1.18303034\n",
      "Epoch: 301 Loss: 0.32456531   Theta_2_1_0: -0.63497710 -4.50084986 -1.18752285\n",
      "Epoch: 302 Loss: 0.32382355   Theta_2_1_0: -0.63330004 -4.49369736 -1.19201305\n",
      "Epoch: 303 Loss: 0.32308237   Theta_2_1_0: -0.63162294 -4.48654752 -1.19650091\n",
      "Epoch: 304 Loss: 0.32234178   Theta_2_1_0: -0.62994582 -4.47940035 -1.20098643\n",
      "Epoch: 305 Loss: 0.32160178   Theta_2_1_0: -0.62826867 -4.47225586 -1.20546960\n",
      "Epoch: 306 Loss: 0.32086237   Theta_2_1_0: -0.62659152 -4.46511408 -1.20995041\n",
      "Epoch: 307 Loss: 0.32012357   Theta_2_1_0: -0.62491435 -4.45797503 -1.21442885\n",
      "Epoch: 308 Loss: 0.31938537   Theta_2_1_0: -0.62323718 -4.45083870 -1.21890491\n",
      "Epoch: 309 Loss: 0.31864777   Theta_2_1_0: -0.62156002 -4.44370514 -1.22337857\n",
      "Epoch: 310 Loss: 0.31791078   Theta_2_1_0: -0.61988286 -4.43657434 -1.22784983\n",
      "Epoch: 311 Loss: 0.31717440   Theta_2_1_0: -0.61820572 -4.42944634 -1.23231868\n",
      "Epoch: 312 Loss: 0.31643863   Theta_2_1_0: -0.61652860 -4.42232114 -1.23678510\n",
      "Epoch: 313 Loss: 0.31570349   Theta_2_1_0: -0.61485151 -4.41519876 -1.24124909\n",
      "Epoch: 314 Loss: 0.31496896   Theta_2_1_0: -0.61317444 -4.40807922 -1.24571063\n",
      "Epoch: 315 Loss: 0.31423506   Theta_2_1_0: -0.61149741 -4.40096254 -1.25016971\n",
      "Epoch: 316 Loss: 0.31350179   Theta_2_1_0: -0.60982042 -4.39384873 -1.25462633\n",
      "Epoch: 317 Loss: 0.31276915   Theta_2_1_0: -0.60814347 -4.38673782 -1.25908046\n",
      "Epoch: 318 Loss: 0.31203714   Theta_2_1_0: -0.60646657 -4.37962982 -1.26353210\n",
      "Epoch: 319 Loss: 0.31130577   Theta_2_1_0: -0.60478973 -4.37252474 -1.26798124\n",
      "Epoch: 320 Loss: 0.31057505   Theta_2_1_0: -0.60311294 -4.36542261 -1.27242787\n",
      "Epoch: 321 Loss: 0.30984496   Theta_2_1_0: -0.60143621 -4.35832345 -1.27687197\n",
      "Epoch: 322 Loss: 0.30911553   Theta_2_1_0: -0.59975954 -4.35122727 -1.28131354\n",
      "Epoch: 323 Loss: 0.30838675   Theta_2_1_0: -0.59808295 -4.34413409 -1.28575255\n",
      "Epoch: 324 Loss: 0.30765862   Theta_2_1_0: -0.59640643 -4.33704394 -1.29018901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 325 Loss: 0.30693116   Theta_2_1_0: -0.59472998 -4.32995682 -1.29462289\n",
      "Epoch: 326 Loss: 0.30620435   Theta_2_1_0: -0.59305362 -4.32287275 -1.29905419\n",
      "Epoch: 327 Loss: 0.30547821   Theta_2_1_0: -0.59137734 -4.31579176 -1.30348289\n",
      "Epoch: 328 Loss: 0.30475275   Theta_2_1_0: -0.58970115 -4.30871387 -1.30790899\n",
      "Epoch: 329 Loss: 0.30402795   Theta_2_1_0: -0.58802505 -4.30163909 -1.31233246\n",
      "Epoch: 330 Loss: 0.30330383   Theta_2_1_0: -0.58634904 -4.29456744 -1.31675331\n",
      "Epoch: 331 Loss: 0.30258039   Theta_2_1_0: -0.58467314 -4.28749895 -1.32117151\n",
      "Epoch: 332 Loss: 0.30185763   Theta_2_1_0: -0.58299734 -4.28043362 -1.32558706\n",
      "Epoch: 333 Loss: 0.30113556   Theta_2_1_0: -0.58132165 -4.27337148 -1.32999993\n",
      "Epoch: 334 Loss: 0.30041418   Theta_2_1_0: -0.57964607 -4.26631256 -1.33441013\n",
      "Epoch: 335 Loss: 0.29969350   Theta_2_1_0: -0.57797060 -4.25925686 -1.33881764\n",
      "Epoch: 336 Loss: 0.29897351   Theta_2_1_0: -0.57629525 -4.25220441 -1.34322244\n",
      "Epoch: 337 Loss: 0.29825423   Theta_2_1_0: -0.57462003 -4.24515522 -1.34762452\n",
      "Epoch: 338 Loss: 0.29753565   Theta_2_1_0: -0.57294493 -4.23810933 -1.35202387\n",
      "Epoch: 339 Loss: 0.29681778   Theta_2_1_0: -0.57126996 -4.23106674 -1.35642048\n",
      "Epoch: 340 Loss: 0.29610062   Theta_2_1_0: -0.56959512 -4.22402748 -1.36081434\n",
      "Epoch: 341 Loss: 0.29538417   Theta_2_1_0: -0.56792041 -4.21699157 -1.36520543\n",
      "Epoch: 342 Loss: 0.29466845   Theta_2_1_0: -0.56624585 -4.20995902 -1.36959373\n",
      "Epoch: 343 Loss: 0.29395345   Theta_2_1_0: -0.56457143 -4.20292986 -1.37397925\n",
      "Epoch: 344 Loss: 0.29323918   Theta_2_1_0: -0.56289716 -4.19590411 -1.37836196\n",
      "Epoch: 345 Loss: 0.29252564   Theta_2_1_0: -0.56122304 -4.18888179 -1.38274185\n",
      "Epoch: 346 Loss: 0.29181283   Theta_2_1_0: -0.55954908 -4.18186291 -1.38711891\n",
      "Epoch: 347 Loss: 0.29110076   Theta_2_1_0: -0.55787527 -4.17484750 -1.39149312\n",
      "Epoch: 348 Loss: 0.29038943   Theta_2_1_0: -0.55620163 -4.16783559 -1.39586448\n",
      "Epoch: 349 Loss: 0.28967885   Theta_2_1_0: -0.55452815 -4.16082718 -1.40023296\n",
      "Epoch: 350 Loss: 0.28896902   Theta_2_1_0: -0.55285484 -4.15382230 -1.40459856\n",
      "Epoch: 351 Loss: 0.28825994   Theta_2_1_0: -0.55118171 -4.14682098 -1.40896127\n",
      "Epoch: 352 Loss: 0.28755162   Theta_2_1_0: -0.54950875 -4.13982322 -1.41332107\n",
      "Epoch: 353 Loss: 0.28684406   Theta_2_1_0: -0.54783597 -4.13282906 -1.41767794\n",
      "Epoch: 354 Loss: 0.28613726   Theta_2_1_0: -0.54616338 -4.12583852 -1.42203188\n",
      "Epoch: 355 Loss: 0.28543124   Theta_2_1_0: -0.54449098 -4.11885161 -1.42638286\n",
      "Epoch: 356 Loss: 0.28472598   Theta_2_1_0: -0.54281877 -4.11186836 -1.43073089\n",
      "Epoch: 357 Loss: 0.28402150   Theta_2_1_0: -0.54114676 -4.10488878 -1.43507594\n",
      "Epoch: 358 Loss: 0.28331780   Theta_2_1_0: -0.53947494 -4.09791291 -1.43941800\n",
      "Epoch: 359 Loss: 0.28261488   Theta_2_1_0: -0.53780334 -4.09094075 -1.44375705\n",
      "Epoch: 360 Loss: 0.28191276   Theta_2_1_0: -0.53613194 -4.08397234 -1.44809309\n",
      "Epoch: 361 Loss: 0.28121142   Theta_2_1_0: -0.53446075 -4.07700769 -1.45242610\n",
      "Epoch: 362 Loss: 0.28051088   Theta_2_1_0: -0.53278978 -4.07004682 -1.45675607\n",
      "Epoch: 363 Loss: 0.27981113   Theta_2_1_0: -0.53111902 -4.06308977 -1.46108297\n",
      "Epoch: 364 Loss: 0.27911219   Theta_2_1_0: -0.52944850 -4.05613654 -1.46540681\n",
      "Epoch: 365 Loss: 0.27841406   Theta_2_1_0: -0.52777820 -4.04918716 -1.46972757\n",
      "Epoch: 366 Loss: 0.27771673   Theta_2_1_0: -0.52610813 -4.04224166 -1.47404522\n",
      "Epoch: 367 Loss: 0.27702023   Theta_2_1_0: -0.52443830 -4.03530005 -1.47835976\n",
      "Epoch: 368 Loss: 0.27632454   Theta_2_1_0: -0.52276871 -4.02836236 -1.48267118\n",
      "Epoch: 369 Loss: 0.27562967   Theta_2_1_0: -0.52109937 -4.02142860 -1.48697946\n",
      "Epoch: 370 Loss: 0.27493563   Theta_2_1_0: -0.51943027 -4.01449881 -1.49128459\n",
      "Epoch: 371 Loss: 0.27424241   Theta_2_1_0: -0.51776143 -4.00757300 -1.49558654\n",
      "Epoch: 372 Loss: 0.27355004   Theta_2_1_0: -0.51609285 -4.00065120 -1.49988532\n",
      "Epoch: 373 Loss: 0.27285850   Theta_2_1_0: -0.51442452 -3.99373342 -1.50418090\n",
      "Epoch: 374 Loss: 0.27216780   Theta_2_1_0: -0.51275647 -3.98681970 -1.50847328\n",
      "Epoch: 375 Loss: 0.27147794   Theta_2_1_0: -0.51108868 -3.97991005 -1.51276243\n",
      "Epoch: 376 Loss: 0.27078894   Theta_2_1_0: -0.50942117 -3.97300450 -1.51704834\n",
      "Epoch: 377 Loss: 0.27010079   Theta_2_1_0: -0.50775393 -3.96610306 -1.52133101\n",
      "Epoch: 378 Loss: 0.26941350   Theta_2_1_0: -0.50608698 -3.95920577 -1.52561040\n",
      "Epoch: 379 Loss: 0.26872707   Theta_2_1_0: -0.50442032 -3.95231264 -1.52988653\n",
      "Epoch: 380 Loss: 0.26804150   Theta_2_1_0: -0.50275395 -3.94542369 -1.53415935\n",
      "Epoch: 381 Loss: 0.26735681   Theta_2_1_0: -0.50108787 -3.93853896 -1.53842887\n",
      "Epoch: 382 Loss: 0.26667299   Theta_2_1_0: -0.49942210 -3.93165846 -1.54269507\n",
      "Epoch: 383 Loss: 0.26599004   Theta_2_1_0: -0.49775663 -3.92478222 -1.54695794\n",
      "Epoch: 384 Loss: 0.26530798   Theta_2_1_0: -0.49609147 -3.91791026 -1.55121745\n",
      "Epoch: 385 Loss: 0.26462680   Theta_2_1_0: -0.49442663 -3.91104260 -1.55547361\n",
      "Epoch: 386 Loss: 0.26394651   Theta_2_1_0: -0.49276210 -3.90417926 -1.55972638\n",
      "Epoch: 387 Loss: 0.26326711   Theta_2_1_0: -0.49109790 -3.89732028 -1.56397577\n",
      "Epoch: 388 Loss: 0.26258861   Theta_2_1_0: -0.48943403 -3.89046566 -1.56822174\n",
      "Epoch: 389 Loss: 0.26191101   Theta_2_1_0: -0.48777049 -3.88361544 -1.57246430\n",
      "Epoch: 390 Loss: 0.26123432   Theta_2_1_0: -0.48610729 -3.87676965 -1.57670342\n",
      "Epoch: 391 Loss: 0.26055853   Theta_2_1_0: -0.48444443 -3.86992829 -1.58093910\n",
      "Epoch: 392 Loss: 0.25988366   Theta_2_1_0: -0.48278191 -3.86309140 -1.58517131\n",
      "Epoch: 393 Loss: 0.25920970   Theta_2_1_0: -0.48111975 -3.85625900 -1.58940005\n",
      "Epoch: 394 Loss: 0.25853666   Theta_2_1_0: -0.47945795 -3.84943112 -1.59362529\n",
      "Epoch: 395 Loss: 0.25786455   Theta_2_1_0: -0.47779650 -3.84260777 -1.59784703\n",
      "Epoch: 396 Loss: 0.25719337   Theta_2_1_0: -0.47613542 -3.83578899 -1.60206525\n",
      "Epoch: 397 Loss: 0.25652312   Theta_2_1_0: -0.47447472 -3.82897479 -1.60627993\n",
      "Epoch: 398 Loss: 0.25585381   Theta_2_1_0: -0.47281439 -3.82216520 -1.61049107\n",
      "Epoch: 399 Loss: 0.25518543   Theta_2_1_0: -0.47115443 -3.81536024 -1.61469864\n",
      "Epoch: 400 Loss: 0.25451800   Theta_2_1_0: -0.46949487 -3.80855994 -1.61890264\n",
      "Epoch: 401 Loss: 0.25385152   Theta_2_1_0: -0.46783570 -3.80176432 -1.62310305\n",
      "Epoch: 402 Loss: 0.25318600   Theta_2_1_0: -0.46617692 -3.79497340 -1.62729985\n",
      "Epoch: 403 Loss: 0.25252142   Theta_2_1_0: -0.46451854 -3.78818722 -1.63149303\n",
      "Epoch: 404 Loss: 0.25185781   Theta_2_1_0: -0.46286056 -3.78140578 -1.63568258\n",
      "Epoch: 405 Loss: 0.25119516   Theta_2_1_0: -0.46120300 -3.77462913 -1.63986848\n",
      "Epoch: 406 Loss: 0.25053348   Theta_2_1_0: -0.45954585 -3.76785728 -1.64405072\n",
      "Epoch: 407 Loss: 0.24987277   Theta_2_1_0: -0.45788912 -3.76109025 -1.64822928\n",
      "Epoch: 408 Loss: 0.24921304   Theta_2_1_0: -0.45623282 -3.75432807 -1.65240415\n",
      "Epoch: 409 Loss: 0.24855429   Theta_2_1_0: -0.45457695 -3.74757077 -1.65657532\n",
      "Epoch: 410 Loss: 0.24789652   Theta_2_1_0: -0.45292151 -3.74081837 -1.66074276\n",
      "Epoch: 411 Loss: 0.24723973   Theta_2_1_0: -0.45126652 -3.73407089 -1.66490648\n",
      "Epoch: 412 Loss: 0.24658394   Theta_2_1_0: -0.44961197 -3.72732836 -1.66906644\n",
      "Epoch: 413 Loss: 0.24592914   Theta_2_1_0: -0.44795787 -3.72059080 -1.67322265\n",
      "Epoch: 414 Loss: 0.24527535   Theta_2_1_0: -0.44630423 -3.71385824 -1.67737508\n",
      "Epoch: 415 Loss: 0.24462255   Theta_2_1_0: -0.44465105 -3.70713071 -1.68152372\n",
      "Epoch: 416 Loss: 0.24397077   Theta_2_1_0: -0.44299834 -3.70040821 -1.68566856\n",
      "Epoch: 417 Loss: 0.24331999   Theta_2_1_0: -0.44134610 -3.69369079 -1.68980957\n",
      "Epoch: 418 Loss: 0.24267023   Theta_2_1_0: -0.43969433 -3.68697847 -1.69394676\n",
      "Epoch: 419 Loss: 0.24202148   Theta_2_1_0: -0.43804305 -3.68027126 -1.69808010\n",
      "Epoch: 420 Loss: 0.24137376   Theta_2_1_0: -0.43639226 -3.67356920 -1.70220958\n",
      "Epoch: 421 Loss: 0.24072706   Theta_2_1_0: -0.43474196 -3.66687231 -1.70633519\n",
      "Epoch: 422 Loss: 0.24008140   Theta_2_1_0: -0.43309215 -3.66018062 -1.71045691\n",
      "Epoch: 423 Loss: 0.23943676   Theta_2_1_0: -0.43144286 -3.65349414 -1.71457472\n",
      "Epoch: 424 Loss: 0.23879317   Theta_2_1_0: -0.42979407 -3.64681291 -1.71868862\n",
      "Epoch: 425 Loss: 0.23815061   Theta_2_1_0: -0.42814579 -3.64013695 -1.72279860\n",
      "Epoch: 426 Loss: 0.23750910   Theta_2_1_0: -0.42649804 -3.63346628 -1.72690462\n",
      "Epoch: 427 Loss: 0.23686864   Theta_2_1_0: -0.42485081 -3.62680093 -1.73100670\n",
      "Epoch: 428 Loss: 0.23622923   Theta_2_1_0: -0.42320412 -3.62014092 -1.73510480\n",
      "Epoch: 429 Loss: 0.23559088   Theta_2_1_0: -0.42155796 -3.61348628 -1.73919891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430 Loss: 0.23495359   Theta_2_1_0: -0.41991234 -3.60683704 -1.74328903\n",
      "Epoch: 431 Loss: 0.23431736   Theta_2_1_0: -0.41826727 -3.60019321 -1.74737513\n",
      "Epoch: 432 Loss: 0.23368220   Theta_2_1_0: -0.41662275 -3.59355483 -1.75145721\n",
      "Epoch: 433 Loss: 0.23304811   Theta_2_1_0: -0.41497879 -3.58692191 -1.75553525\n",
      "Epoch: 434 Loss: 0.23241509   Theta_2_1_0: -0.41333539 -3.58029449 -1.75960924\n",
      "Epoch: 435 Loss: 0.23178315   Theta_2_1_0: -0.41169257 -3.57367259 -1.76367916\n",
      "Epoch: 436 Loss: 0.23115229   Theta_2_1_0: -0.41005032 -3.56705623 -1.76774501\n",
      "Epoch: 437 Loss: 0.23052252   Theta_2_1_0: -0.40840865 -3.56044544 -1.77180676\n",
      "Epoch: 438 Loss: 0.22989384   Theta_2_1_0: -0.40676756 -3.55384024 -1.77586440\n",
      "Epoch: 439 Loss: 0.22926625   Theta_2_1_0: -0.40512707 -3.54724066 -1.77991792\n",
      "Epoch: 440 Loss: 0.22863976   Theta_2_1_0: -0.40348718 -3.54064672 -1.78396731\n",
      "Epoch: 441 Loss: 0.22801437   Theta_2_1_0: -0.40184788 -3.53405846 -1.78801256\n",
      "Epoch: 442 Loss: 0.22739008   Theta_2_1_0: -0.40020920 -3.52747588 -1.79205364\n",
      "Epoch: 443 Loss: 0.22676690   Theta_2_1_0: -0.39857113 -3.52089903 -1.79609056\n",
      "Epoch: 444 Loss: 0.22614483   Theta_2_1_0: -0.39693369 -3.51432791 -1.80012328\n",
      "Epoch: 445 Loss: 0.22552387   Theta_2_1_0: -0.39529687 -3.50776257 -1.80415181\n",
      "Epoch: 446 Loss: 0.22490403   Theta_2_1_0: -0.39366068 -3.50120302 -1.80817613\n",
      "Epoch: 447 Loss: 0.22428531   Theta_2_1_0: -0.39202512 -3.49464929 -1.81219623\n",
      "Epoch: 448 Loss: 0.22366772   Theta_2_1_0: -0.39039021 -3.48810140 -1.81621208\n",
      "Epoch: 449 Loss: 0.22305125   Theta_2_1_0: -0.38875595 -3.48155938 -1.82022369\n",
      "Epoch: 450 Loss: 0.22243591   Theta_2_1_0: -0.38712234 -3.47502326 -1.82423104\n",
      "Epoch: 451 Loss: 0.22182171   Theta_2_1_0: -0.38548940 -3.46849305 -1.82823411\n",
      "Epoch: 452 Loss: 0.22120865   Theta_2_1_0: -0.38385712 -3.46196879 -1.83223289\n",
      "Epoch: 453 Loss: 0.22059673   Theta_2_1_0: -0.38222551 -3.45545050 -1.83622738\n",
      "Epoch: 454 Loss: 0.21998596   Theta_2_1_0: -0.38059458 -3.44893820 -1.84021755\n",
      "Epoch: 455 Loss: 0.21937633   Theta_2_1_0: -0.37896433 -3.44243191 -1.84420340\n",
      "Epoch: 456 Loss: 0.21876786   Theta_2_1_0: -0.37733477 -3.43593168 -1.84818491\n",
      "Epoch: 457 Loss: 0.21816053   Theta_2_1_0: -0.37570591 -3.42943751 -1.85216207\n",
      "Epoch: 458 Loss: 0.21755437   Theta_2_1_0: -0.37407774 -3.42294943 -1.85613487\n",
      "Epoch: 459 Loss: 0.21694937   Theta_2_1_0: -0.37245028 -3.41646747 -1.86010329\n",
      "Epoch: 460 Loss: 0.21634553   Theta_2_1_0: -0.37082354 -3.40999166 -1.86406734\n",
      "Epoch: 461 Loss: 0.21574287   Theta_2_1_0: -0.36919751 -3.40352201 -1.86802698\n",
      "Epoch: 462 Loss: 0.21514137   Theta_2_1_0: -0.36757221 -3.39705856 -1.87198222\n",
      "Epoch: 463 Loss: 0.21454105   Theta_2_1_0: -0.36594764 -3.39060133 -1.87593303\n",
      "Epoch: 464 Loss: 0.21394190   Theta_2_1_0: -0.36432380 -3.38415033 -1.87987941\n",
      "Epoch: 465 Loss: 0.21334394   Theta_2_1_0: -0.36270070 -3.37770561 -1.88382135\n",
      "Epoch: 466 Loss: 0.21274715   Theta_2_1_0: -0.36107835 -3.37126718 -1.88775883\n",
      "Epoch: 467 Loss: 0.21215156   Theta_2_1_0: -0.35945676 -3.36483506 -1.89169185\n",
      "Epoch: 468 Loss: 0.21155715   Theta_2_1_0: -0.35783592 -3.35840929 -1.89562039\n",
      "Epoch: 469 Loss: 0.21096394   Theta_2_1_0: -0.35621585 -3.35198988 -1.89954443\n",
      "Epoch: 470 Loss: 0.21037193   Theta_2_1_0: -0.35459655 -3.34557686 -1.90346398\n",
      "Epoch: 471 Loss: 0.20978111   Theta_2_1_0: -0.35297802 -3.33917026 -1.90737902\n",
      "Epoch: 472 Loss: 0.20919149   Theta_2_1_0: -0.35136028 -3.33277010 -1.91128953\n",
      "Epoch: 473 Loss: 0.20860308   Theta_2_1_0: -0.34974333 -3.32637641 -1.91519551\n",
      "Epoch: 474 Loss: 0.20801588   Theta_2_1_0: -0.34812717 -3.31998920 -1.91909694\n",
      "Epoch: 475 Loss: 0.20742989   Theta_2_1_0: -0.34651181 -3.31360851 -1.92299382\n",
      "Epoch: 476 Loss: 0.20684511   Theta_2_1_0: -0.34489726 -3.30723435 -1.92688613\n",
      "Epoch: 477 Loss: 0.20626154   Theta_2_1_0: -0.34328352 -3.30086676 -1.93077387\n",
      "Epoch: 478 Loss: 0.20567920   Theta_2_1_0: -0.34167059 -3.29450576 -1.93465702\n",
      "Epoch: 479 Loss: 0.20509808   Theta_2_1_0: -0.34005849 -3.28815137 -1.93853557\n",
      "Epoch: 480 Loss: 0.20451818   Theta_2_1_0: -0.33844722 -3.28180361 -1.94240952\n",
      "Epoch: 481 Loss: 0.20393951   Theta_2_1_0: -0.33683679 -3.27546251 -1.94627885\n",
      "Epoch: 482 Loss: 0.20336207   Theta_2_1_0: -0.33522719 -3.26912810 -1.95014355\n",
      "Epoch: 483 Loss: 0.20278587   Theta_2_1_0: -0.33361845 -3.26280040 -1.95400361\n",
      "Epoch: 484 Loss: 0.20221090   Theta_2_1_0: -0.33201055 -3.25647943 -1.95785902\n",
      "Epoch: 485 Loss: 0.20163717   Theta_2_1_0: -0.33040352 -3.25016522 -1.96170978\n",
      "Epoch: 486 Loss: 0.20106468   Theta_2_1_0: -0.32879735 -3.24385778 -1.96555587\n",
      "Epoch: 487 Loss: 0.20049343   Theta_2_1_0: -0.32719205 -3.23755716 -1.96939728\n",
      "Epoch: 488 Loss: 0.19992343   Theta_2_1_0: -0.32558763 -3.23126336 -1.97323401\n",
      "Epoch: 489 Loss: 0.19935467   Theta_2_1_0: -0.32398409 -3.22497642 -1.97706604\n",
      "Epoch: 490 Loss: 0.19878717   Theta_2_1_0: -0.32238144 -3.21869635 -1.98089337\n",
      "Epoch: 491 Loss: 0.19822092   Theta_2_1_0: -0.32077968 -3.21242318 -1.98471598\n",
      "Epoch: 492 Loss: 0.19765593   Theta_2_1_0: -0.31917883 -3.20615694 -1.98853387\n",
      "Epoch: 493 Loss: 0.19709220   Theta_2_1_0: -0.31757888 -3.19989764 -1.99234703\n",
      "Epoch: 494 Loss: 0.19652973   Theta_2_1_0: -0.31597984 -3.19364532 -1.99615544\n",
      "Epoch: 495 Loss: 0.19596852   Theta_2_1_0: -0.31438171 -3.18739999 -1.99995911\n",
      "Epoch: 496 Loss: 0.19540858   Theta_2_1_0: -0.31278452 -3.18116169 -2.00375802\n",
      "Epoch: 497 Loss: 0.19484990   Theta_2_1_0: -0.31118825 -3.17493042 -2.00755217\n",
      "Epoch: 498 Loss: 0.19429250   Theta_2_1_0: -0.30959291 -3.16870622 -2.01134153\n",
      "Epoch: 499 Loss: 0.19373636   Theta_2_1_0: -0.30799852 -3.16248912 -2.01512612\n",
      "Epoch: 500 Loss: 0.19318151   Theta_2_1_0: -0.30640508 -3.15627912 -2.01890591\n",
      "Epoch: 501 Loss: 0.19262793   Theta_2_1_0: -0.30481258 -3.15007626 -2.02268091\n",
      "Epoch: 502 Loss: 0.19207563   Theta_2_1_0: -0.30322105 -3.14388056 -2.02645109\n",
      "Epoch: 503 Loss: 0.19152461   Theta_2_1_0: -0.30163048 -3.13769204 -2.03021647\n",
      "Epoch: 504 Loss: 0.19097487   Theta_2_1_0: -0.30004088 -3.13151073 -2.03397701\n",
      "Epoch: 505 Loss: 0.19042642   Theta_2_1_0: -0.29845226 -3.12533665 -2.03773273\n",
      "Epoch: 506 Loss: 0.18987926   Theta_2_1_0: -0.29686461 -3.11916982 -2.04148361\n",
      "Epoch: 507 Loss: 0.18933339   Theta_2_1_0: -0.29527796 -3.11301027 -2.04522965\n",
      "Epoch: 508 Loss: 0.18878881   Theta_2_1_0: -0.29369230 -3.10685801 -2.04897083\n",
      "Epoch: 509 Loss: 0.18824552   Theta_2_1_0: -0.29210763 -3.10071308 -2.05270715\n",
      "Epoch: 510 Loss: 0.18770353   Theta_2_1_0: -0.29052398 -3.09457549 -2.05643860\n",
      "Epoch: 511 Loss: 0.18716284   Theta_2_1_0: -0.28894133 -3.08844526 -2.06016518\n",
      "Epoch: 512 Loss: 0.18662345   Theta_2_1_0: -0.28735970 -3.08232243 -2.06388688\n",
      "Epoch: 513 Loss: 0.18608535   Theta_2_1_0: -0.28577909 -3.07620700 -2.06760370\n",
      "Epoch: 514 Loss: 0.18554857   Theta_2_1_0: -0.28419951 -3.07009901 -2.07131561\n",
      "Epoch: 515 Loss: 0.18501308   Theta_2_1_0: -0.28262096 -3.06399848 -2.07502263\n",
      "Epoch: 516 Loss: 0.18447891   Theta_2_1_0: -0.28104345 -3.05790542 -2.07872474\n",
      "Epoch: 517 Loss: 0.18394604   Theta_2_1_0: -0.27946699 -3.05181987 -2.08242194\n",
      "Epoch: 518 Loss: 0.18341448   Theta_2_1_0: -0.27789157 -3.04574184 -2.08611422\n",
      "Epoch: 519 Loss: 0.18288424   Theta_2_1_0: -0.27631721 -3.03967135 -2.08980158\n",
      "Epoch: 520 Loss: 0.18235531   Theta_2_1_0: -0.27474392 -3.03360844 -2.09348400\n",
      "Epoch: 521 Loss: 0.18182769   Theta_2_1_0: -0.27317169 -3.02755311 -2.09716149\n",
      "Epoch: 522 Loss: 0.18130139   Theta_2_1_0: -0.27160053 -3.02150540 -2.10083403\n",
      "Epoch: 523 Loss: 0.18077641   Theta_2_1_0: -0.27003046 -3.01546532 -2.10450163\n",
      "Epoch: 524 Loss: 0.18025275   Theta_2_1_0: -0.26846146 -3.00943289 -2.10816428\n",
      "Epoch: 525 Loss: 0.17973042   Theta_2_1_0: -0.26689356 -3.00340815 -2.11182196\n",
      "Epoch: 526 Loss: 0.17920940   Theta_2_1_0: -0.26532675 -2.99739110 -2.11547469\n",
      "Epoch: 527 Loss: 0.17868971   Theta_2_1_0: -0.26376105 -2.99138177 -2.11912244\n",
      "Epoch: 528 Loss: 0.17817135   Theta_2_1_0: -0.26219645 -2.98538019 -2.12276522\n",
      "Epoch: 529 Loss: 0.17765431   Theta_2_1_0: -0.26063296 -2.97938637 -2.12640303\n",
      "Epoch: 530 Loss: 0.17713860   Theta_2_1_0: -0.25907059 -2.97340033 -2.13003585\n",
      "Epoch: 531 Loss: 0.17662423   Theta_2_1_0: -0.25750934 -2.96742210 -2.13366368\n",
      "Epoch: 532 Loss: 0.17611118   Theta_2_1_0: -0.25594922 -2.96145170 -2.13728653\n",
      "Epoch: 533 Loss: 0.17559947   Theta_2_1_0: -0.25439024 -2.95548915 -2.14090438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 534 Loss: 0.17508909   Theta_2_1_0: -0.25283239 -2.94953446 -2.14451722\n",
      "Epoch: 535 Loss: 0.17458004   Theta_2_1_0: -0.25127569 -2.94358767 -2.14812507\n",
      "Epoch: 536 Loss: 0.17407234   Theta_2_1_0: -0.24972015 -2.93764879 -2.15172790\n",
      "Epoch: 537 Loss: 0.17356597   Theta_2_1_0: -0.24816575 -2.93171785 -2.15532573\n",
      "Epoch: 538 Loss: 0.17306094   Theta_2_1_0: -0.24661252 -2.92579486 -2.15891854\n",
      "Epoch: 539 Loss: 0.17255725   Theta_2_1_0: -0.24506046 -2.91987984 -2.16250633\n",
      "Epoch: 540 Loss: 0.17205489   Theta_2_1_0: -0.24350956 -2.91397282 -2.16608910\n",
      "Epoch: 541 Loss: 0.17155389   Theta_2_1_0: -0.24195985 -2.90807381 -2.16966684\n",
      "Epoch: 542 Loss: 0.17105422   Theta_2_1_0: -0.24041132 -2.90218284 -2.17323956\n",
      "Epoch: 543 Loss: 0.17055590   Theta_2_1_0: -0.23886397 -2.89629993 -2.17680724\n",
      "Epoch: 544 Loss: 0.17005892   Theta_2_1_0: -0.23731782 -2.89042509 -2.18036989\n",
      "Epoch: 545 Loss: 0.16956329   Theta_2_1_0: -0.23577287 -2.88455835 -2.18392750\n",
      "Epoch: 546 Loss: 0.16906901   Theta_2_1_0: -0.23422912 -2.87869973 -2.18748007\n",
      "Epoch: 547 Loss: 0.16857607   Theta_2_1_0: -0.23268658 -2.87284924 -2.19102760\n",
      "Epoch: 548 Loss: 0.16808448   Theta_2_1_0: -0.23114526 -2.86700692 -2.19457009\n",
      "Epoch: 549 Loss: 0.16759424   Theta_2_1_0: -0.22960516 -2.86117277 -2.19810753\n",
      "Epoch: 550 Loss: 0.16710535   Theta_2_1_0: -0.22806628 -2.85534682 -2.20163992\n",
      "Epoch: 551 Loss: 0.16661782   Theta_2_1_0: -0.22652863 -2.84952908 -2.20516725\n",
      "Epoch: 552 Loss: 0.16613163   Theta_2_1_0: -0.22499222 -2.84371958 -2.20868954\n",
      "Epoch: 553 Loss: 0.16564679   Theta_2_1_0: -0.22345705 -2.83791834 -2.21220677\n",
      "Epoch: 554 Loss: 0.16516331   Theta_2_1_0: -0.22192312 -2.83212538 -2.21571894\n",
      "Epoch: 555 Loss: 0.16468118   Theta_2_1_0: -0.22039044 -2.82634071 -2.21922606\n",
      "Epoch: 556 Loss: 0.16420041   Theta_2_1_0: -0.21885903 -2.82056435 -2.22272811\n",
      "Epoch: 557 Loss: 0.16372099   Theta_2_1_0: -0.21732887 -2.81479633 -2.22622511\n",
      "Epoch: 558 Loss: 0.16324292   Theta_2_1_0: -0.21579998 -2.80903667 -2.22971704\n",
      "Epoch: 559 Loss: 0.16276621   Theta_2_1_0: -0.21427236 -2.80328537 -2.23320391\n",
      "Epoch: 560 Loss: 0.16229086   Theta_2_1_0: -0.21274601 -2.79754247 -2.23668571\n",
      "Epoch: 561 Loss: 0.16181686   Theta_2_1_0: -0.21122095 -2.79180798 -2.24016245\n",
      "Epoch: 562 Loss: 0.16134422   Theta_2_1_0: -0.20969717 -2.78608192 -2.24363413\n",
      "Epoch: 563 Loss: 0.16087294   Theta_2_1_0: -0.20817469 -2.78036430 -2.24710073\n",
      "Epoch: 564 Loss: 0.16040302   Theta_2_1_0: -0.20665350 -2.77465515 -2.25056227\n",
      "Epoch: 565 Loss: 0.15993445   Theta_2_1_0: -0.20513362 -2.76895449 -2.25401875\n",
      "Epoch: 566 Loss: 0.15946724   Theta_2_1_0: -0.20361504 -2.76326233 -2.25747015\n",
      "Epoch: 567 Loss: 0.15900139   Theta_2_1_0: -0.20209777 -2.75757870 -2.26091649\n",
      "Epoch: 568 Loss: 0.15853690   Theta_2_1_0: -0.20058182 -2.75190361 -2.26435776\n",
      "Epoch: 569 Loss: 0.15807377   Theta_2_1_0: -0.19906718 -2.74623707 -2.26779397\n",
      "Epoch: 570 Loss: 0.15761200   Theta_2_1_0: -0.19755388 -2.74057912 -2.27122510\n",
      "Epoch: 571 Loss: 0.15715158   Theta_2_1_0: -0.19604190 -2.73492975 -2.27465117\n",
      "Epoch: 572 Loss: 0.15669253   Theta_2_1_0: -0.19453126 -2.72928901 -2.27807218\n",
      "Epoch: 573 Loss: 0.15623484   Theta_2_1_0: -0.19302197 -2.72365689 -2.28148811\n",
      "Epoch: 574 Loss: 0.15577850   Theta_2_1_0: -0.19151401 -2.71803343 -2.28489899\n",
      "Epoch: 575 Loss: 0.15532353   Theta_2_1_0: -0.19000741 -2.71241863 -2.28830479\n",
      "Epoch: 576 Loss: 0.15486992   Theta_2_1_0: -0.18850216 -2.70681252 -2.29170554\n",
      "Epoch: 577 Loss: 0.15441766   Theta_2_1_0: -0.18699827 -2.70121511 -2.29510122\n",
      "Epoch: 578 Loss: 0.15396677   Theta_2_1_0: -0.18549574 -2.69562642 -2.29849184\n",
      "Epoch: 579 Loss: 0.15351724   Theta_2_1_0: -0.18399459 -2.69004647 -2.30187740\n",
      "Epoch: 580 Loss: 0.15306906   Theta_2_1_0: -0.18249480 -2.68447527 -2.30525790\n",
      "Epoch: 581 Loss: 0.15262225   Theta_2_1_0: -0.18099640 -2.67891285 -2.30863335\n",
      "Epoch: 582 Loss: 0.15217680   Theta_2_1_0: -0.17949938 -2.67335922 -2.31200374\n",
      "Epoch: 583 Loss: 0.15173270   Theta_2_1_0: -0.17800374 -2.66781439 -2.31536907\n",
      "Epoch: 584 Loss: 0.15128997   Theta_2_1_0: -0.17650950 -2.66227839 -2.31872936\n",
      "Epoch: 585 Loss: 0.15084859   Theta_2_1_0: -0.17501665 -2.65675123 -2.32208459\n",
      "Epoch: 586 Loss: 0.15040858   Theta_2_1_0: -0.17352521 -2.65123293 -2.32543477\n",
      "Epoch: 587 Loss: 0.14996992   Theta_2_1_0: -0.17203517 -2.64572351 -2.32877991\n",
      "Epoch: 588 Loss: 0.14953262   Theta_2_1_0: -0.17054654 -2.64022297 -2.33212001\n",
      "Epoch: 589 Loss: 0.14909668   Theta_2_1_0: -0.16905933 -2.63473134 -2.33545506\n",
      "Epoch: 590 Loss: 0.14866209   Theta_2_1_0: -0.16757353 -2.62924864 -2.33878507\n",
      "Epoch: 591 Loss: 0.14822886   Theta_2_1_0: -0.16608916 -2.62377488 -2.34211005\n",
      "Epoch: 592 Loss: 0.14779700   Theta_2_1_0: -0.16460622 -2.61831008 -2.34542999\n",
      "Epoch: 593 Loss: 0.14736648   Theta_2_1_0: -0.16312470 -2.61285425 -2.34874491\n",
      "Epoch: 594 Loss: 0.14693733   Theta_2_1_0: -0.16164463 -2.60740742 -2.35205479\n",
      "Epoch: 595 Loss: 0.14650952   Theta_2_1_0: -0.16016600 -2.60196959 -2.35535965\n",
      "Epoch: 596 Loss: 0.14608308   Theta_2_1_0: -0.15868881 -2.59654078 -2.35865949\n",
      "Epoch: 597 Loss: 0.14565799   Theta_2_1_0: -0.15721307 -2.59112101 -2.36195430\n",
      "Epoch: 598 Loss: 0.14523425   Theta_2_1_0: -0.15573879 -2.58571029 -2.36524411\n",
      "Epoch: 599 Loss: 0.14481187   Theta_2_1_0: -0.15426597 -2.58030865 -2.36852890\n",
      "Epoch: 600 Loss: 0.14439084   Theta_2_1_0: -0.15279461 -2.57491609 -2.37180868\n",
      "Epoch: 601 Loss: 0.14397116   Theta_2_1_0: -0.15132471 -2.56953264 -2.37508345\n",
      "Epoch: 602 Loss: 0.14355284   Theta_2_1_0: -0.14985629 -2.56415830 -2.37835323\n",
      "Epoch: 603 Loss: 0.14313586   Theta_2_1_0: -0.14838934 -2.55879309 -2.38161800\n",
      "Epoch: 604 Loss: 0.14272024   Theta_2_1_0: -0.14692387 -2.55343703 -2.38487779\n",
      "Epoch: 605 Loss: 0.14230596   Theta_2_1_0: -0.14545989 -2.54809014 -2.38813258\n",
      "Epoch: 606 Loss: 0.14189304   Theta_2_1_0: -0.14399740 -2.54275243 -2.39138239\n",
      "Epoch: 607 Loss: 0.14148146   Theta_2_1_0: -0.14253639 -2.53742391 -2.39462721\n",
      "Epoch: 608 Loss: 0.14107123   Theta_2_1_0: -0.14107689 -2.53210460 -2.39786706\n",
      "Epoch: 609 Loss: 0.14066235   Theta_2_1_0: -0.13961888 -2.52679451 -2.40110193\n",
      "Epoch: 610 Loss: 0.14025482   Theta_2_1_0: -0.13816238 -2.52149366 -2.40433184\n",
      "Epoch: 611 Loss: 0.13984863   Theta_2_1_0: -0.13670739 -2.51620207 -2.40755678\n",
      "Epoch: 612 Loss: 0.13944378   Theta_2_1_0: -0.13525391 -2.51091974 -2.41077676\n",
      "Epoch: 613 Loss: 0.13904028   Theta_2_1_0: -0.13380195 -2.50564670 -2.41399179\n",
      "Epoch: 614 Loss: 0.13863812   Theta_2_1_0: -0.13235151 -2.50038296 -2.41720186\n",
      "Epoch: 615 Loss: 0.13823730   Theta_2_1_0: -0.13090259 -2.49512853 -2.42040699\n",
      "Epoch: 616 Loss: 0.13783782   Theta_2_1_0: -0.12945520 -2.48988343 -2.42360719\n",
      "Epoch: 617 Loss: 0.13743969   Theta_2_1_0: -0.12800935 -2.48464767 -2.42680244\n",
      "Epoch: 618 Loss: 0.13704289   Theta_2_1_0: -0.12656503 -2.47942126 -2.42999277\n",
      "Epoch: 619 Loss: 0.13664743   Theta_2_1_0: -0.12512225 -2.47420423 -2.43317817\n",
      "Epoch: 620 Loss: 0.13625330   Theta_2_1_0: -0.12368102 -2.46899658 -2.43635865\n",
      "Epoch: 621 Loss: 0.13586051   Theta_2_1_0: -0.12224134 -2.46379832 -2.43953422\n",
      "Epoch: 622 Loss: 0.13546906   Theta_2_1_0: -0.12080321 -2.45860948 -2.44270488\n",
      "Epoch: 623 Loss: 0.13507894   Theta_2_1_0: -0.11936663 -2.45343007 -2.44587064\n",
      "Epoch: 624 Loss: 0.13469015   Theta_2_1_0: -0.11793162 -2.44826009 -2.44903150\n",
      "Epoch: 625 Loss: 0.13430269   Theta_2_1_0: -0.11649817 -2.44309957 -2.45218747\n",
      "Epoch: 626 Loss: 0.13391657   Theta_2_1_0: -0.11506628 -2.43794852 -2.45533856\n",
      "Epoch: 627 Loss: 0.13353177   Theta_2_1_0: -0.11363597 -2.43280694 -2.45848476\n",
      "Epoch: 628 Loss: 0.13314830   Theta_2_1_0: -0.11220724 -2.42767486 -2.46162609\n",
      "Epoch: 629 Loss: 0.13276616   Theta_2_1_0: -0.11078008 -2.42255229 -2.46476256\n",
      "Epoch: 630 Loss: 0.13238534   Theta_2_1_0: -0.10935451 -2.41743924 -2.46789416\n",
      "Epoch: 631 Loss: 0.13200584   Theta_2_1_0: -0.10793052 -2.41233572 -2.47102091\n",
      "Epoch: 632 Loss: 0.13162767   Theta_2_1_0: -0.10650812 -2.40724175 -2.47414280\n",
      "Epoch: 633 Loss: 0.13125082   Theta_2_1_0: -0.10508732 -2.40215735 -2.47725986\n",
      "Epoch: 634 Loss: 0.13087529   Theta_2_1_0: -0.10366811 -2.39708251 -2.48037208\n",
      "Epoch: 635 Loss: 0.13050108   Theta_2_1_0: -0.10225051 -2.39201726 -2.48347947\n",
      "Epoch: 636 Loss: 0.13012819   Theta_2_1_0: -0.10083451 -2.38696161 -2.48658204\n",
      "Epoch: 637 Loss: 0.12975661   Theta_2_1_0: -0.09942012 -2.38191557 -2.48967980\n",
      "Epoch: 638 Loss: 0.12938635   Theta_2_1_0: -0.09800734 -2.37687916 -2.49277274\n",
      "Epoch: 639 Loss: 0.12901740   Theta_2_1_0: -0.09659618 -2.37185238 -2.49586088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 640 Loss: 0.12864976   Theta_2_1_0: -0.09518663 -2.36683525 -2.49894423\n",
      "Epoch: 641 Loss: 0.12828344   Theta_2_1_0: -0.09377871 -2.36182779 -2.50202279\n",
      "Epoch: 642 Loss: 0.12791842   Theta_2_1_0: -0.09237242 -2.35682999 -2.50509657\n",
      "Epoch: 643 Loss: 0.12755471   Theta_2_1_0: -0.09096775 -2.35184189 -2.50816557\n",
      "Epoch: 644 Loss: 0.12719231   Theta_2_1_0: -0.08956472 -2.34686348 -2.51122981\n",
      "Epoch: 645 Loss: 0.12683121   Theta_2_1_0: -0.08816333 -2.34189479 -2.51428929\n",
      "Epoch: 646 Loss: 0.12647141   Theta_2_1_0: -0.08676357 -2.33693582 -2.51734401\n",
      "Epoch: 647 Loss: 0.12611291   Theta_2_1_0: -0.08536546 -2.33198658 -2.52039399\n",
      "Epoch: 648 Loss: 0.12575572   Theta_2_1_0: -0.08396900 -2.32704709 -2.52343924\n",
      "Epoch: 649 Loss: 0.12539982   Theta_2_1_0: -0.08257419 -2.32211736 -2.52647975\n",
      "Epoch: 650 Loss: 0.12504522   Theta_2_1_0: -0.08118103 -2.31719739 -2.52951554\n",
      "Epoch: 651 Loss: 0.12469191   Theta_2_1_0: -0.07978953 -2.31228721 -2.53254662\n",
      "Epoch: 652 Loss: 0.12433990   Theta_2_1_0: -0.07839969 -2.30738683 -2.53557299\n",
      "Epoch: 653 Loss: 0.12398918   Theta_2_1_0: -0.07701152 -2.30249624 -2.53859466\n",
      "Epoch: 654 Loss: 0.12363975   Theta_2_1_0: -0.07562501 -2.29761548 -2.54161164\n",
      "Epoch: 655 Loss: 0.12329161   Theta_2_1_0: -0.07424018 -2.29274454 -2.54462394\n",
      "Epoch: 656 Loss: 0.12294475   Theta_2_1_0: -0.07285702 -2.28788344 -2.54763156\n",
      "Epoch: 657 Loss: 0.12259918   Theta_2_1_0: -0.07147553 -2.28303219 -2.55063452\n",
      "Epoch: 658 Loss: 0.12225489   Theta_2_1_0: -0.07009573 -2.27819080 -2.55363282\n",
      "Epoch: 659 Loss: 0.12191189   Theta_2_1_0: -0.06871761 -2.27335928 -2.55662646\n",
      "Epoch: 660 Loss: 0.12157016   Theta_2_1_0: -0.06734118 -2.26853764 -2.55961547\n",
      "Epoch: 661 Loss: 0.12122971   Theta_2_1_0: -0.06596644 -2.26372590 -2.56259984\n",
      "Epoch: 662 Loss: 0.12089053   Theta_2_1_0: -0.06459340 -2.25892406 -2.56557958\n",
      "Epoch: 663 Loss: 0.12055264   Theta_2_1_0: -0.06322205 -2.25413214 -2.56855471\n",
      "Epoch: 664 Loss: 0.12021601   Theta_2_1_0: -0.06185240 -2.24935014 -2.57152523\n",
      "Epoch: 665 Loss: 0.11988065   Theta_2_1_0: -0.06048446 -2.24457808 -2.57449115\n",
      "Epoch: 666 Loss: 0.11954656   Theta_2_1_0: -0.05911822 -2.23981596 -2.57745248\n",
      "Epoch: 667 Loss: 0.11921374   Theta_2_1_0: -0.05775369 -2.23506380 -2.58040922\n",
      "Epoch: 668 Loss: 0.11888218   Theta_2_1_0: -0.05639088 -2.23032161 -2.58336139\n",
      "Epoch: 669 Loss: 0.11855189   Theta_2_1_0: -0.05502978 -2.22558939 -2.58630899\n",
      "Epoch: 670 Loss: 0.11822286   Theta_2_1_0: -0.05367041 -2.22086716 -2.58925204\n",
      "Epoch: 671 Loss: 0.11789508   Theta_2_1_0: -0.05231275 -2.21615492 -2.59219054\n",
      "Epoch: 672 Loss: 0.11756856   Theta_2_1_0: -0.05095682 -2.21145270 -2.59512450\n",
      "Epoch: 673 Loss: 0.11724330   Theta_2_1_0: -0.04960262 -2.20676049 -2.59805393\n",
      "Epoch: 674 Loss: 0.11691929   Theta_2_1_0: -0.04825016 -2.20207830 -2.60097884\n",
      "Epoch: 675 Loss: 0.11659653   Theta_2_1_0: -0.04689942 -2.19740615 -2.60389924\n",
      "Epoch: 676 Loss: 0.11627502   Theta_2_1_0: -0.04555043 -2.19274405 -2.60681513\n",
      "Epoch: 677 Loss: 0.11595476   Theta_2_1_0: -0.04420318 -2.18809200 -2.60972653\n",
      "Epoch: 678 Loss: 0.11563574   Theta_2_1_0: -0.04285767 -2.18345001 -2.61263345\n",
      "Epoch: 679 Loss: 0.11531797   Theta_2_1_0: -0.04151391 -2.17881810 -2.61553589\n",
      "Epoch: 680 Loss: 0.11500143   Theta_2_1_0: -0.04017190 -2.17419627 -2.61843386\n",
      "Epoch: 681 Loss: 0.11468614   Theta_2_1_0: -0.03883164 -2.16958454 -2.62132738\n",
      "Epoch: 682 Loss: 0.11437208   Theta_2_1_0: -0.03749314 -2.16498290 -2.62421645\n",
      "Epoch: 683 Loss: 0.11405925   Theta_2_1_0: -0.03615640 -2.16039137 -2.62710109\n",
      "Epoch: 684 Loss: 0.11374766   Theta_2_1_0: -0.03482142 -2.15580996 -2.62998129\n",
      "Epoch: 685 Loss: 0.11343730   Theta_2_1_0: -0.03348821 -2.15123868 -2.63285708\n",
      "Epoch: 686 Loss: 0.11312816   Theta_2_1_0: -0.03215677 -2.14667754 -2.63572845\n",
      "Epoch: 687 Loss: 0.11282025   Theta_2_1_0: -0.03082709 -2.14212653 -2.63859543\n",
      "Epoch: 688 Loss: 0.11251356   Theta_2_1_0: -0.02949920 -2.13758569 -2.64145801\n",
      "Epoch: 689 Loss: 0.11220810   Theta_2_1_0: -0.02817308 -2.13305500 -2.64431622\n",
      "Epoch: 690 Loss: 0.11190385   Theta_2_1_0: -0.02684873 -2.12853448 -2.64717005\n",
      "Epoch: 691 Loss: 0.11160082   Theta_2_1_0: -0.02552618 -2.12402414 -2.65001953\n",
      "Epoch: 692 Loss: 0.11129901   Theta_2_1_0: -0.02420541 -2.11952399 -2.65286465\n",
      "Epoch: 693 Loss: 0.11099841   Theta_2_1_0: -0.02288642 -2.11503403 -2.65570543\n",
      "Epoch: 694 Loss: 0.11069901   Theta_2_1_0: -0.02156923 -2.11055428 -2.65854188\n",
      "Epoch: 695 Loss: 0.11040083   Theta_2_1_0: -0.02025383 -2.10608473 -2.66137401\n",
      "Epoch: 696 Loss: 0.11010385   Theta_2_1_0: -0.01894024 -2.10162540 -2.66420183\n",
      "Epoch: 697 Loss: 0.10980807   Theta_2_1_0: -0.01762844 -2.09717630 -2.66702534\n",
      "Epoch: 698 Loss: 0.10951350   Theta_2_1_0: -0.01631844 -2.09273743 -2.66984456\n",
      "Epoch: 699 Loss: 0.10922012   Theta_2_1_0: -0.01501025 -2.08830880 -2.67265951\n",
      "Epoch: 700 Loss: 0.10892794   Theta_2_1_0: -0.01370387 -2.08389042 -2.67547018\n",
      "Epoch: 701 Loss: 0.10863695   Theta_2_1_0: -0.01239930 -2.07948229 -2.67827658\n",
      "Epoch: 702 Loss: 0.10834716   Theta_2_1_0: -0.01109655 -2.07508443 -2.68107874\n",
      "Epoch: 703 Loss: 0.10805855   Theta_2_1_0: -0.00979561 -2.07069683 -2.68387666\n",
      "Epoch: 704 Loss: 0.10777113   Theta_2_1_0: -0.00849649 -2.06631952 -2.68667034\n",
      "Epoch: 705 Loss: 0.10748489   Theta_2_1_0: -0.00719920 -2.06195249 -2.68945980\n",
      "Epoch: 706 Loss: 0.10719983   Theta_2_1_0: -0.00590373 -2.05759574 -2.69224506\n",
      "Epoch: 707 Loss: 0.10691596   Theta_2_1_0: -0.00461009 -2.05324930 -2.69502611\n",
      "Epoch: 708 Loss: 0.10663326   Theta_2_1_0: -0.00331828 -2.04891316 -2.69780298\n",
      "Epoch: 709 Loss: 0.10635173   Theta_2_1_0: -0.00202831 -2.04458733 -2.70057566\n",
      "Epoch: 710 Loss: 0.10607138   Theta_2_1_0: -0.00074017 -2.04027182 -2.70334418\n",
      "Epoch: 711 Loss: 0.10579220   Theta_2_1_0: 0.00054613 -2.03596663 -2.70610853\n",
      "Epoch: 712 Loss: 0.10551418   Theta_2_1_0: 0.00183059 -2.03167177 -2.70886874\n",
      "Epoch: 713 Loss: 0.10523733   Theta_2_1_0: 0.00311320 -2.02738725 -2.71162481\n",
      "Epoch: 714 Loss: 0.10496163   Theta_2_1_0: 0.00439397 -2.02311307 -2.71437675\n",
      "Epoch: 715 Loss: 0.10468710   Theta_2_1_0: 0.00567288 -2.01884924 -2.71712458\n",
      "Epoch: 716 Loss: 0.10441373   Theta_2_1_0: 0.00694994 -2.01459576 -2.71986830\n",
      "Epoch: 717 Loss: 0.10414151   Theta_2_1_0: 0.00822515 -2.01035265 -2.72260793\n",
      "Epoch: 718 Loss: 0.10387044   Theta_2_1_0: 0.00949850 -2.00611990 -2.72534347\n",
      "Epoch: 719 Loss: 0.10360051   Theta_2_1_0: 0.01076999 -2.00189752 -2.72807493\n",
      "Epoch: 720 Loss: 0.10333174   Theta_2_1_0: 0.01203961 -1.99768551 -2.73080233\n",
      "Epoch: 721 Loss: 0.10306411   Theta_2_1_0: 0.01330737 -1.99348389 -2.73352568\n",
      "Epoch: 722 Loss: 0.10279762   Theta_2_1_0: 0.01457326 -1.98929266 -2.73624499\n",
      "Epoch: 723 Loss: 0.10253227   Theta_2_1_0: 0.01583728 -1.98511182 -2.73896026\n",
      "Epoch: 724 Loss: 0.10226805   Theta_2_1_0: 0.01709942 -1.98094138 -2.74167151\n",
      "Epoch: 725 Loss: 0.10200497   Theta_2_1_0: 0.01835969 -1.97678134 -2.74437876\n",
      "Epoch: 726 Loss: 0.10174302   Theta_2_1_0: 0.01961808 -1.97263171 -2.74708200\n",
      "Epoch: 727 Loss: 0.10148220   Theta_2_1_0: 0.02087459 -1.96849250 -2.74978126\n",
      "Epoch: 728 Loss: 0.10122250   Theta_2_1_0: 0.02212921 -1.96436370 -2.75247653\n",
      "Epoch: 729 Loss: 0.10096392   Theta_2_1_0: 0.02338195 -1.96024532 -2.75516784\n",
      "Epoch: 730 Loss: 0.10070647   Theta_2_1_0: 0.02463279 -1.95613737 -2.75785520\n",
      "Epoch: 731 Loss: 0.10045013   Theta_2_1_0: 0.02588175 -1.95203985 -2.76053860\n",
      "Epoch: 732 Loss: 0.10019491   Theta_2_1_0: 0.02712881 -1.94795277 -2.76321808\n",
      "Epoch: 733 Loss: 0.09994079   Theta_2_1_0: 0.02837397 -1.94387613 -2.76589363\n",
      "Epoch: 734 Loss: 0.09968779   Theta_2_1_0: 0.02961724 -1.93980993 -2.76856526\n",
      "Epoch: 735 Loss: 0.09943589   Theta_2_1_0: 0.03085860 -1.93575418 -2.77123300\n",
      "Epoch: 736 Loss: 0.09918510   Theta_2_1_0: 0.03209806 -1.93170888 -2.77389684\n",
      "Epoch: 737 Loss: 0.09893541   Theta_2_1_0: 0.03333561 -1.92767403 -2.77655681\n",
      "Epoch: 738 Loss: 0.09868681   Theta_2_1_0: 0.03457125 -1.92364965 -2.77921290\n",
      "Epoch: 739 Loss: 0.09843931   Theta_2_1_0: 0.03580498 -1.91963573 -2.78186514\n",
      "Epoch: 740 Loss: 0.09819291   Theta_2_1_0: 0.03703679 -1.91563227 -2.78451353\n",
      "Epoch: 741 Loss: 0.09794759   Theta_2_1_0: 0.03826669 -1.91163929 -2.78715808\n",
      "Epoch: 742 Loss: 0.09770336   Theta_2_1_0: 0.03949467 -1.90765677 -2.78979881\n",
      "Epoch: 743 Loss: 0.09746021   Theta_2_1_0: 0.04072072 -1.90368474 -2.79243573\n",
      "Epoch: 744 Loss: 0.09721814   Theta_2_1_0: 0.04194485 -1.89972318 -2.79506884\n",
      "Epoch: 745 Loss: 0.09697716   Theta_2_1_0: 0.04316706 -1.89577211 -2.79769816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 746 Loss: 0.09673724   Theta_2_1_0: 0.04438733 -1.89183152 -2.80032370\n",
      "Epoch: 747 Loss: 0.09649840   Theta_2_1_0: 0.04560568 -1.88790141 -2.80294547\n",
      "Epoch: 748 Loss: 0.09626063   Theta_2_1_0: 0.04682209 -1.88398180 -2.80556348\n",
      "Epoch: 749 Loss: 0.09602393   Theta_2_1_0: 0.04803656 -1.88007268 -2.80817774\n",
      "Epoch: 750 Loss: 0.09578829   Theta_2_1_0: 0.04924910 -1.87617406 -2.81078827\n",
      "Epoch: 751 Loss: 0.09555371   Theta_2_1_0: 0.05045969 -1.87228593 -2.81339507\n",
      "Epoch: 752 Loss: 0.09532019   Theta_2_1_0: 0.05166834 -1.86840831 -2.81599815\n",
      "Epoch: 753 Loss: 0.09508773   Theta_2_1_0: 0.05287504 -1.86454118 -2.81859754\n",
      "Epoch: 754 Loss: 0.09485631   Theta_2_1_0: 0.05407980 -1.86068456 -2.82119323\n",
      "Epoch: 755 Loss: 0.09462595   Theta_2_1_0: 0.05528260 -1.85683845 -2.82378524\n",
      "Epoch: 756 Loss: 0.09439663   Theta_2_1_0: 0.05648346 -1.85300284 -2.82637358\n",
      "Epoch: 757 Loss: 0.09416836   Theta_2_1_0: 0.05768235 -1.84917774 -2.82895826\n",
      "Epoch: 758 Loss: 0.09394112   Theta_2_1_0: 0.05887929 -1.84536315 -2.83153929\n",
      "Epoch: 759 Loss: 0.09371493   Theta_2_1_0: 0.06007427 -1.84155907 -2.83411669\n",
      "Epoch: 760 Loss: 0.09348977   Theta_2_1_0: 0.06126729 -1.83776551 -2.83669046\n",
      "Epoch: 761 Loss: 0.09326564   Theta_2_1_0: 0.06245835 -1.83398246 -2.83926061\n",
      "Epoch: 762 Loss: 0.09304254   Theta_2_1_0: 0.06364743 -1.83020992 -2.84182717\n",
      "Epoch: 763 Loss: 0.09282046   Theta_2_1_0: 0.06483455 -1.82644790 -2.84439013\n",
      "Epoch: 764 Loss: 0.09259941   Theta_2_1_0: 0.06601970 -1.82269640 -2.84694951\n",
      "Epoch: 765 Loss: 0.09237938   Theta_2_1_0: 0.06720287 -1.81895542 -2.84950532\n",
      "Epoch: 766 Loss: 0.09216036   Theta_2_1_0: 0.06838407 -1.81522495 -2.85205757\n",
      "Epoch: 767 Loss: 0.09194236   Theta_2_1_0: 0.06956329 -1.81150500 -2.85460628\n",
      "Epoch: 768 Loss: 0.09172536   Theta_2_1_0: 0.07074053 -1.80779557 -2.85715145\n",
      "Epoch: 769 Loss: 0.09150938   Theta_2_1_0: 0.07191579 -1.80409666 -2.85969309\n",
      "Epoch: 770 Loss: 0.09129440   Theta_2_1_0: 0.07308906 -1.80040827 -2.86223122\n",
      "Epoch: 771 Loss: 0.09108042   Theta_2_1_0: 0.07426035 -1.79673040 -2.86476584\n",
      "Epoch: 772 Loss: 0.09086744   Theta_2_1_0: 0.07542964 -1.79306305 -2.86729698\n",
      "Epoch: 773 Loss: 0.09065545   Theta_2_1_0: 0.07659695 -1.78940621 -2.86982463\n",
      "Epoch: 774 Loss: 0.09044446   Theta_2_1_0: 0.07776226 -1.78575990 -2.87234882\n",
      "Epoch: 775 Loss: 0.09023446   Theta_2_1_0: 0.07892558 -1.78212410 -2.87486955\n",
      "Epoch: 776 Loss: 0.09002544   Theta_2_1_0: 0.08008690 -1.77849882 -2.87738682\n",
      "Epoch: 777 Loss: 0.08981740   Theta_2_1_0: 0.08124623 -1.77488405 -2.87990067\n",
      "Epoch: 778 Loss: 0.08961035   Theta_2_1_0: 0.08240355 -1.77127980 -2.88241109\n",
      "Epoch: 779 Loss: 0.08940427   Theta_2_1_0: 0.08355886 -1.76768607 -2.88491809\n",
      "Epoch: 780 Loss: 0.08919917   Theta_2_1_0: 0.08471217 -1.76410285 -2.88742169\n",
      "Epoch: 781 Loss: 0.08899503   Theta_2_1_0: 0.08586348 -1.76053014 -2.88992190\n",
      "Epoch: 782 Loss: 0.08879187   Theta_2_1_0: 0.08701277 -1.75696794 -2.89241873\n",
      "Epoch: 783 Loss: 0.08858966   Theta_2_1_0: 0.08816005 -1.75341625 -2.89491220\n",
      "Epoch: 784 Loss: 0.08838842   Theta_2_1_0: 0.08930532 -1.74987507 -2.89740230\n",
      "Epoch: 785 Loss: 0.08818814   Theta_2_1_0: 0.09044857 -1.74634439 -2.89988905\n",
      "Epoch: 786 Loss: 0.08798881   Theta_2_1_0: 0.09158980 -1.74282422 -2.90237247\n",
      "Epoch: 787 Loss: 0.08779044   Theta_2_1_0: 0.09272902 -1.73931455 -2.90485257\n",
      "Epoch: 788 Loss: 0.08759301   Theta_2_1_0: 0.09386621 -1.73581538 -2.90732935\n",
      "Epoch: 789 Loss: 0.08739653   Theta_2_1_0: 0.09500138 -1.73232671 -2.90980283\n",
      "Epoch: 790 Loss: 0.08720098   Theta_2_1_0: 0.09613452 -1.72884853 -2.91227301\n",
      "Epoch: 791 Loss: 0.08700638   Theta_2_1_0: 0.09726564 -1.72538085 -2.91473992\n",
      "Epoch: 792 Loss: 0.08681272   Theta_2_1_0: 0.09839472 -1.72192365 -2.91720355\n",
      "Epoch: 793 Loss: 0.08661999   Theta_2_1_0: 0.09952178 -1.71847695 -2.91966393\n",
      "Epoch: 794 Loss: 0.08642818   Theta_2_1_0: 0.10064680 -1.71504072 -2.92212106\n",
      "Epoch: 795 Loss: 0.08623731   Theta_2_1_0: 0.10176978 -1.71161498 -2.92457495\n",
      "Epoch: 796 Loss: 0.08604735   Theta_2_1_0: 0.10289073 -1.70819972 -2.92702562\n",
      "Epoch: 797 Loss: 0.08585832   Theta_2_1_0: 0.10400964 -1.70479493 -2.92947307\n",
      "Epoch: 798 Loss: 0.08567020   Theta_2_1_0: 0.10512651 -1.70140062 -2.93191731\n",
      "Epoch: 799 Loss: 0.08548300   Theta_2_1_0: 0.10624134 -1.69801677 -2.93435837\n",
      "Epoch: 800 Loss: 0.08529671   Theta_2_1_0: 0.10735412 -1.69464339 -2.93679624\n",
      "Epoch: 801 Loss: 0.08511132   Theta_2_1_0: 0.10846486 -1.69128047 -2.93923094\n",
      "Epoch: 802 Loss: 0.08492684   Theta_2_1_0: 0.10957354 -1.68792800 -2.94166248\n",
      "Epoch: 803 Loss: 0.08474326   Theta_2_1_0: 0.11068018 -1.68458599 -2.94409088\n",
      "Epoch: 804 Loss: 0.08456057   Theta_2_1_0: 0.11178477 -1.68125443 -2.94651613\n",
      "Epoch: 805 Loss: 0.08437879   Theta_2_1_0: 0.11288730 -1.67793331 -2.94893826\n",
      "Epoch: 806 Loss: 0.08419789   Theta_2_1_0: 0.11398778 -1.67462263 -2.95135726\n",
      "Epoch: 807 Loss: 0.08401788   Theta_2_1_0: 0.11508621 -1.67132239 -2.95377317\n",
      "Epoch: 808 Loss: 0.08383875   Theta_2_1_0: 0.11618257 -1.66803257 -2.95618598\n",
      "Epoch: 809 Loss: 0.08366050   Theta_2_1_0: 0.11727688 -1.66475319 -2.95859570\n",
      "Epoch: 810 Loss: 0.08348314   Theta_2_1_0: 0.11836912 -1.66148422 -2.96100235\n",
      "Epoch: 811 Loss: 0.08330664   Theta_2_1_0: 0.11945930 -1.65822567 -2.96340594\n",
      "Epoch: 812 Loss: 0.08313102   Theta_2_1_0: 0.12054742 -1.65497753 -2.96580648\n",
      "Epoch: 813 Loss: 0.08295627   Theta_2_1_0: 0.12163347 -1.65173980 -2.96820397\n",
      "Epoch: 814 Loss: 0.08278238   Theta_2_1_0: 0.12271745 -1.64851247 -2.97059844\n",
      "Epoch: 815 Loss: 0.08260935   Theta_2_1_0: 0.12379936 -1.64529553 -2.97298988\n",
      "Epoch: 816 Loss: 0.08243719   Theta_2_1_0: 0.12487920 -1.64208898 -2.97537832\n",
      "Epoch: 817 Loss: 0.08226587   Theta_2_1_0: 0.12595697 -1.63889281 -2.97776375\n",
      "Epoch: 818 Loss: 0.08209541   Theta_2_1_0: 0.12703267 -1.63570702 -2.98014620\n",
      "Epoch: 819 Loss: 0.08192580   Theta_2_1_0: 0.12810629 -1.63253160 -2.98252568\n",
      "Epoch: 820 Loss: 0.08175703   Theta_2_1_0: 0.12917783 -1.62936654 -2.98490218\n",
      "Epoch: 821 Loss: 0.08158911   Theta_2_1_0: 0.13024730 -1.62621184 -2.98727573\n",
      "Epoch: 822 Loss: 0.08142202   Theta_2_1_0: 0.13131468 -1.62306750 -2.98964634\n",
      "Epoch: 823 Loss: 0.08125577   Theta_2_1_0: 0.13237999 -1.61993349 -2.99201401\n",
      "Epoch: 824 Loss: 0.08109035   Theta_2_1_0: 0.13344321 -1.61680983 -2.99437875\n",
      "Epoch: 825 Loss: 0.08092576   Theta_2_1_0: 0.13450435 -1.61369650 -2.99674058\n",
      "Epoch: 826 Loss: 0.08076199   Theta_2_1_0: 0.13556340 -1.61059349 -2.99909951\n",
      "Epoch: 827 Loss: 0.08059905   Theta_2_1_0: 0.13662037 -1.60750079 -3.00145555\n",
      "Epoch: 828 Loss: 0.08043693   Theta_2_1_0: 0.13767525 -1.60441841 -3.00380870\n",
      "Epoch: 829 Loss: 0.08027562   Theta_2_1_0: 0.13872804 -1.60134633 -3.00615898\n",
      "Epoch: 830 Loss: 0.08011512   Theta_2_1_0: 0.13977874 -1.59828454 -3.00850640\n",
      "Epoch: 831 Loss: 0.07995543   Theta_2_1_0: 0.14082735 -1.59523304 -3.01085097\n",
      "Epoch: 832 Loss: 0.07979655   Theta_2_1_0: 0.14187387 -1.59219182 -3.01319270\n",
      "Epoch: 833 Loss: 0.07963847   Theta_2_1_0: 0.14291829 -1.58916087 -3.01553159\n",
      "Epoch: 834 Loss: 0.07948119   Theta_2_1_0: 0.14396062 -1.58614019 -3.01786767\n",
      "Epoch: 835 Loss: 0.07932471   Theta_2_1_0: 0.14500085 -1.58312975 -3.02020094\n",
      "Epoch: 836 Loss: 0.07916902   Theta_2_1_0: 0.14603898 -1.58012957 -3.02253140\n",
      "Epoch: 837 Loss: 0.07901412   Theta_2_1_0: 0.14707502 -1.57713962 -3.02485908\n",
      "Epoch: 838 Loss: 0.07886000   Theta_2_1_0: 0.14810895 -1.57415990 -3.02718398\n",
      "Epoch: 839 Loss: 0.07870667   Theta_2_1_0: 0.14914079 -1.57119040 -3.02950610\n",
      "Epoch: 840 Loss: 0.07855411   Theta_2_1_0: 0.15017053 -1.56823111 -3.03182547\n",
      "Epoch: 841 Loss: 0.07840233   Theta_2_1_0: 0.15119816 -1.56528202 -3.03414209\n",
      "Epoch: 842 Loss: 0.07825133   Theta_2_1_0: 0.15222369 -1.56234313 -3.03645598\n",
      "Epoch: 843 Loss: 0.07810109   Theta_2_1_0: 0.15324711 -1.55941442 -3.03876713\n",
      "Epoch: 844 Loss: 0.07795162   Theta_2_1_0: 0.15426843 -1.55649589 -3.04107556\n",
      "Epoch: 845 Loss: 0.07780291   Theta_2_1_0: 0.15528764 -1.55358752 -3.04338129\n",
      "Epoch: 846 Loss: 0.07765496   Theta_2_1_0: 0.15630475 -1.55068930 -3.04568432\n",
      "Epoch: 847 Loss: 0.07750777   Theta_2_1_0: 0.15731974 -1.54780123 -3.04798465\n",
      "Epoch: 848 Loss: 0.07736133   Theta_2_1_0: 0.15833263 -1.54492329 -3.05028231\n",
      "Epoch: 849 Loss: 0.07721564   Theta_2_1_0: 0.15934341 -1.54205548 -3.05257731\n",
      "Epoch: 850 Loss: 0.07707070   Theta_2_1_0: 0.16035208 -1.53919779 -3.05486964\n",
      "Epoch: 851 Loss: 0.07692650   Theta_2_1_0: 0.16135864 -1.53635020 -3.05715932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 852 Loss: 0.07678304   Theta_2_1_0: 0.16236308 -1.53351270 -3.05944636\n",
      "Epoch: 853 Loss: 0.07664031   Theta_2_1_0: 0.16336541 -1.53068529 -3.06173078\n",
      "Epoch: 854 Loss: 0.07649832   Theta_2_1_0: 0.16436563 -1.52786795 -3.06401257\n",
      "Epoch: 855 Loss: 0.07635706   Theta_2_1_0: 0.16536374 -1.52506067 -3.06629175\n",
      "Epoch: 856 Loss: 0.07621652   Theta_2_1_0: 0.16635973 -1.52226344 -3.06856834\n",
      "Epoch: 857 Loss: 0.07607671   Theta_2_1_0: 0.16735360 -1.51947625 -3.07084233\n",
      "Epoch: 858 Loss: 0.07593762   Theta_2_1_0: 0.16834536 -1.51669909 -3.07311374\n",
      "Epoch: 859 Loss: 0.07579924   Theta_2_1_0: 0.16933500 -1.51393195 -3.07538258\n",
      "Epoch: 860 Loss: 0.07566158   Theta_2_1_0: 0.17032253 -1.51117481 -3.07764886\n",
      "Epoch: 861 Loss: 0.07552462   Theta_2_1_0: 0.17130793 -1.50842766 -3.07991259\n",
      "Epoch: 862 Loss: 0.07538838   Theta_2_1_0: 0.17229122 -1.50569050 -3.08217377\n",
      "Epoch: 863 Loss: 0.07525283   Theta_2_1_0: 0.17327239 -1.50296331 -3.08443243\n",
      "Epoch: 864 Loss: 0.07511799   Theta_2_1_0: 0.17425145 -1.50024607 -3.08668855\n",
      "Epoch: 865 Loss: 0.07498384   Theta_2_1_0: 0.17522838 -1.49753878 -3.08894217\n",
      "Epoch: 866 Loss: 0.07485039   Theta_2_1_0: 0.17620319 -1.49484142 -3.09119327\n",
      "Epoch: 867 Loss: 0.07471763   Theta_2_1_0: 0.17717588 -1.49215399 -3.09344189\n",
      "Epoch: 868 Loss: 0.07458555   Theta_2_1_0: 0.17814646 -1.48947646 -3.09568801\n",
      "Epoch: 869 Loss: 0.07445416   Theta_2_1_0: 0.17911491 -1.48680883 -3.09793166\n",
      "Epoch: 870 Loss: 0.07432345   Theta_2_1_0: 0.18008124 -1.48415108 -3.10017284\n",
      "Epoch: 871 Loss: 0.07419341   Theta_2_1_0: 0.18104545 -1.48150320 -3.10241157\n",
      "Epoch: 872 Loss: 0.07406405   Theta_2_1_0: 0.18200754 -1.47886518 -3.10464784\n",
      "Epoch: 873 Loss: 0.07393536   Theta_2_1_0: 0.18296751 -1.47623700 -3.10688168\n",
      "Epoch: 874 Loss: 0.07380734   Theta_2_1_0: 0.18392535 -1.47361865 -3.10911308\n",
      "Epoch: 875 Loss: 0.07367998   Theta_2_1_0: 0.18488108 -1.47101012 -3.11134206\n",
      "Epoch: 876 Loss: 0.07355329   Theta_2_1_0: 0.18583468 -1.46841139 -3.11356863\n",
      "Epoch: 877 Loss: 0.07342725   Theta_2_1_0: 0.18678616 -1.46582245 -3.11579280\n",
      "Epoch: 878 Loss: 0.07330186   Theta_2_1_0: 0.18773552 -1.46324329 -3.11801457\n",
      "Epoch: 879 Loss: 0.07317713   Theta_2_1_0: 0.18868275 -1.46067389 -3.12023395\n",
      "Epoch: 880 Loss: 0.07305304   Theta_2_1_0: 0.18962787 -1.45811423 -3.12245096\n",
      "Epoch: 881 Loss: 0.07292960   Theta_2_1_0: 0.19057086 -1.45556431 -3.12466560\n",
      "Epoch: 882 Loss: 0.07280680   Theta_2_1_0: 0.19151173 -1.45302411 -3.12687788\n",
      "Epoch: 883 Loss: 0.07268464   Theta_2_1_0: 0.19245048 -1.45049362 -3.12908781\n",
      "Epoch: 884 Loss: 0.07256311   Theta_2_1_0: 0.19338711 -1.44797281 -3.13129540\n",
      "Epoch: 885 Loss: 0.07244222   Theta_2_1_0: 0.19432162 -1.44546168 -3.13350066\n",
      "Epoch: 886 Loss: 0.07232195   Theta_2_1_0: 0.19525400 -1.44296021 -3.13570359\n",
      "Epoch: 887 Loss: 0.07220231   Theta_2_1_0: 0.19618427 -1.44046839 -3.13790421\n",
      "Epoch: 888 Loss: 0.07208330   Theta_2_1_0: 0.19711241 -1.43798619 -3.14010252\n",
      "Epoch: 889 Loss: 0.07196490   Theta_2_1_0: 0.19803843 -1.43551362 -3.14229854\n",
      "Epoch: 890 Loss: 0.07184712   Theta_2_1_0: 0.19896234 -1.43305064 -3.14449226\n",
      "Epoch: 891 Loss: 0.07172995   Theta_2_1_0: 0.19988412 -1.43059725 -3.14668371\n",
      "Epoch: 892 Loss: 0.07161338   Theta_2_1_0: 0.20080379 -1.42815342 -3.14887288\n",
      "Epoch: 893 Loss: 0.07149743   Theta_2_1_0: 0.20172133 -1.42571915 -3.15105979\n",
      "Epoch: 894 Loss: 0.07138208   Theta_2_1_0: 0.20263676 -1.42329442 -3.15324444\n",
      "Epoch: 895 Loss: 0.07126733   Theta_2_1_0: 0.20355007 -1.42087921 -3.15542685\n",
      "Epoch: 896 Loss: 0.07115318   Theta_2_1_0: 0.20446126 -1.41847351 -3.15760701\n",
      "Epoch: 897 Loss: 0.07103962   Theta_2_1_0: 0.20537034 -1.41607730 -3.15978495\n",
      "Epoch: 898 Loss: 0.07092665   Theta_2_1_0: 0.20627730 -1.41369056 -3.16196067\n",
      "Epoch: 899 Loss: 0.07081426   Theta_2_1_0: 0.20718214 -1.41131328 -3.16413417\n",
      "Epoch: 900 Loss: 0.07070247   Theta_2_1_0: 0.20808487 -1.40894544 -3.16630546\n",
      "Epoch: 901 Loss: 0.07059125   Theta_2_1_0: 0.20898549 -1.40658702 -3.16847456\n",
      "Epoch: 902 Loss: 0.07048061   Theta_2_1_0: 0.20988399 -1.40423801 -3.17064147\n",
      "Epoch: 903 Loss: 0.07037055   Theta_2_1_0: 0.21078037 -1.40189839 -3.17280620\n",
      "Epoch: 904 Loss: 0.07026106   Theta_2_1_0: 0.21167465 -1.39956815 -3.17496876\n",
      "Epoch: 905 Loss: 0.07015214   Theta_2_1_0: 0.21256682 -1.39724727 -3.17712915\n",
      "Epoch: 906 Loss: 0.07004378   Theta_2_1_0: 0.21345687 -1.39493572 -3.17928739\n",
      "Epoch: 907 Loss: 0.06993599   Theta_2_1_0: 0.21434481 -1.39263350 -3.18144347\n",
      "Epoch: 908 Loss: 0.06982875   Theta_2_1_0: 0.21523065 -1.39034058 -3.18359742\n",
      "Epoch: 909 Loss: 0.06972207   Theta_2_1_0: 0.21611438 -1.38805696 -3.18574923\n",
      "Epoch: 910 Loss: 0.06961595   Theta_2_1_0: 0.21699600 -1.38578260 -3.18789891\n",
      "Epoch: 911 Loss: 0.06951038   Theta_2_1_0: 0.21787552 -1.38351749 -3.19004648\n",
      "Epoch: 912 Loss: 0.06940535   Theta_2_1_0: 0.21875293 -1.38126163 -3.19219194\n",
      "Epoch: 913 Loss: 0.06930087   Theta_2_1_0: 0.21962823 -1.37901497 -3.19433530\n",
      "Epoch: 914 Loss: 0.06919693   Theta_2_1_0: 0.22050144 -1.37677752 -3.19647656\n",
      "Epoch: 915 Loss: 0.06909352   Theta_2_1_0: 0.22137254 -1.37454925 -3.19861574\n",
      "Epoch: 916 Loss: 0.06899066   Theta_2_1_0: 0.22224155 -1.37233014 -3.20075284\n",
      "Epoch: 917 Loss: 0.06888832   Theta_2_1_0: 0.22310845 -1.37012018 -3.20288787\n",
      "Epoch: 918 Loss: 0.06878651   Theta_2_1_0: 0.22397325 -1.36791935 -3.20502083\n",
      "Epoch: 919 Loss: 0.06868523   Theta_2_1_0: 0.22483596 -1.36572762 -3.20715174\n",
      "Epoch: 920 Loss: 0.06858448   Theta_2_1_0: 0.22569658 -1.36354498 -3.20928059\n",
      "Epoch: 921 Loss: 0.06848424   Theta_2_1_0: 0.22655510 -1.36137142 -3.21140741\n",
      "Epoch: 922 Loss: 0.06838452   Theta_2_1_0: 0.22741152 -1.35920690 -3.21353219\n",
      "Epoch: 923 Loss: 0.06828532   Theta_2_1_0: 0.22826586 -1.35705142 -3.21565495\n",
      "Epoch: 924 Loss: 0.06818663   Theta_2_1_0: 0.22911810 -1.35490496 -3.21777569\n",
      "Epoch: 925 Loss: 0.06808844   Theta_2_1_0: 0.22996826 -1.35276749 -3.21989441\n",
      "Epoch: 926 Loss: 0.06799076   Theta_2_1_0: 0.23081633 -1.35063899 -3.22201113\n",
      "Epoch: 927 Loss: 0.06789358   Theta_2_1_0: 0.23166231 -1.34851945 -3.22412585\n",
      "Epoch: 928 Loss: 0.06779691   Theta_2_1_0: 0.23250621 -1.34640885 -3.22623859\n",
      "Epoch: 929 Loss: 0.06770073   Theta_2_1_0: 0.23334803 -1.34430717 -3.22834934\n",
      "Epoch: 930 Loss: 0.06760504   Theta_2_1_0: 0.23418777 -1.34221439 -3.23045811\n",
      "Epoch: 931 Loss: 0.06750984   Theta_2_1_0: 0.23502543 -1.34013049 -3.23256491\n",
      "Epoch: 932 Loss: 0.06741514   Theta_2_1_0: 0.23586101 -1.33805544 -3.23466975\n",
      "Epoch: 933 Loss: 0.06732091   Theta_2_1_0: 0.23669451 -1.33598924 -3.23677264\n",
      "Epoch: 934 Loss: 0.06722717   Theta_2_1_0: 0.23752594 -1.33393185 -3.23887358\n",
      "Epoch: 935 Loss: 0.06713391   Theta_2_1_0: 0.23835530 -1.33188327 -3.24097258\n",
      "Epoch: 936 Loss: 0.06704113   Theta_2_1_0: 0.23918259 -1.32984346 -3.24306964\n",
      "Epoch: 937 Loss: 0.06694882   Theta_2_1_0: 0.24000780 -1.32781242 -3.24516477\n",
      "Epoch: 938 Loss: 0.06685698   Theta_2_1_0: 0.24083096 -1.32579011 -3.24725799\n",
      "Epoch: 939 Loss: 0.06676560   Theta_2_1_0: 0.24165204 -1.32377652 -3.24934929\n",
      "Epoch: 940 Loss: 0.06667470   Theta_2_1_0: 0.24247107 -1.32177164 -3.25143868\n",
      "Epoch: 941 Loss: 0.06658425   Theta_2_1_0: 0.24328803 -1.31977542 -3.25352617\n",
      "Epoch: 942 Loss: 0.06649427   Theta_2_1_0: 0.24410293 -1.31778787 -3.25561177\n",
      "Epoch: 943 Loss: 0.06640474   Theta_2_1_0: 0.24491578 -1.31580896 -3.25769548\n",
      "Epoch: 944 Loss: 0.06631567   Theta_2_1_0: 0.24572657 -1.31383866 -3.25977731\n",
      "Epoch: 945 Loss: 0.06622705   Theta_2_1_0: 0.24653531 -1.31187695 -3.26185727\n",
      "Epoch: 946 Loss: 0.06613887   Theta_2_1_0: 0.24734200 -1.30992382 -3.26393536\n",
      "Epoch: 947 Loss: 0.06605114   Theta_2_1_0: 0.24814664 -1.30797925 -3.26601158\n",
      "Epoch: 948 Loss: 0.06596386   Theta_2_1_0: 0.24894924 -1.30604320 -3.26808595\n",
      "Epoch: 949 Loss: 0.06587701   Theta_2_1_0: 0.24974978 -1.30411567 -3.27015848\n",
      "Epoch: 950 Loss: 0.06579061   Theta_2_1_0: 0.25054829 -1.30219663 -3.27222916\n",
      "Epoch: 951 Loss: 0.06570464   Theta_2_1_0: 0.25134476 -1.30028605 -3.27429800\n",
      "Epoch: 952 Loss: 0.06561910   Theta_2_1_0: 0.25213919 -1.29838393 -3.27636502\n",
      "Epoch: 953 Loss: 0.06553398   Theta_2_1_0: 0.25293158 -1.29649023 -3.27843021\n",
      "Epoch: 954 Loss: 0.06544930   Theta_2_1_0: 0.25372195 -1.29460493 -3.28049358\n",
      "Epoch: 955 Loss: 0.06536504   Theta_2_1_0: 0.25451028 -1.29272802 -3.28255514\n",
      "Epoch: 956 Loss: 0.06528120   Theta_2_1_0: 0.25529658 -1.29085947 -3.28461490\n",
      "Epoch: 957 Loss: 0.06519778   Theta_2_1_0: 0.25608086 -1.28899926 -3.28667286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 958 Loss: 0.06511478   Theta_2_1_0: 0.25686312 -1.28714737 -3.28872902\n",
      "Epoch: 959 Loss: 0.06503219   Theta_2_1_0: 0.25764336 -1.28530377 -3.29078340\n",
      "Epoch: 960 Loss: 0.06495001   Theta_2_1_0: 0.25842157 -1.28346845 -3.29283600\n",
      "Epoch: 961 Loss: 0.06486824   Theta_2_1_0: 0.25919778 -1.28164138 -3.29488682\n",
      "Epoch: 962 Loss: 0.06478688   Theta_2_1_0: 0.25997197 -1.27982254 -3.29693587\n",
      "Epoch: 963 Loss: 0.06470592   Theta_2_1_0: 0.26074415 -1.27801191 -3.29898316\n",
      "Epoch: 964 Loss: 0.06462536   Theta_2_1_0: 0.26151432 -1.27620946 -3.30102869\n",
      "Epoch: 965 Loss: 0.06454520   Theta_2_1_0: 0.26228249 -1.27441518 -3.30307247\n",
      "Epoch: 966 Loss: 0.06446543   Theta_2_1_0: 0.26304865 -1.27262904 -3.30511450\n",
      "Epoch: 967 Loss: 0.06438605   Theta_2_1_0: 0.26381282 -1.27085102 -3.30715479\n",
      "Epoch: 968 Loss: 0.06430707   Theta_2_1_0: 0.26457499 -1.26908109 -3.30919335\n",
      "Epoch: 969 Loss: 0.06422847   Theta_2_1_0: 0.26533517 -1.26731924 -3.31123018\n",
      "Epoch: 970 Loss: 0.06415026   Theta_2_1_0: 0.26609336 -1.26556544 -3.31326529\n",
      "Epoch: 971 Loss: 0.06407244   Theta_2_1_0: 0.26684955 -1.26381967 -3.31529867\n",
      "Epoch: 972 Loss: 0.06399499   Theta_2_1_0: 0.26760377 -1.26208191 -3.31733035\n",
      "Epoch: 973 Loss: 0.06391792   Theta_2_1_0: 0.26835600 -1.26035213 -3.31936031\n",
      "Epoch: 974 Loss: 0.06384123   Theta_2_1_0: 0.26910625 -1.25863031 -3.32138858\n",
      "Epoch: 975 Loss: 0.06376490   Theta_2_1_0: 0.26985453 -1.25691643 -3.32341515\n",
      "Epoch: 976 Loss: 0.06368895   Theta_2_1_0: 0.27060083 -1.25521047 -3.32544003\n",
      "Epoch: 977 Loss: 0.06361337   Theta_2_1_0: 0.27134517 -1.25351240 -3.32746322\n",
      "Epoch: 978 Loss: 0.06353815   Theta_2_1_0: 0.27208754 -1.25182220 -3.32948473\n",
      "Epoch: 979 Loss: 0.06346330   Theta_2_1_0: 0.27282794 -1.25013984 -3.33150457\n",
      "Epoch: 980 Loss: 0.06338881   Theta_2_1_0: 0.27356638 -1.24846531 -3.33352274\n",
      "Epoch: 981 Loss: 0.06331467   Theta_2_1_0: 0.27430287 -1.24679858 -3.33553924\n",
      "Epoch: 982 Loss: 0.06324090   Theta_2_1_0: 0.27503740 -1.24513962 -3.33755409\n",
      "Epoch: 983 Loss: 0.06316747   Theta_2_1_0: 0.27576998 -1.24348842 -3.33956728\n",
      "Epoch: 984 Loss: 0.06309440   Theta_2_1_0: 0.27650061 -1.24184495 -3.34157882\n",
      "Epoch: 985 Loss: 0.06302167   Theta_2_1_0: 0.27722930 -1.24020919 -3.34358872\n",
      "Epoch: 986 Loss: 0.06294930   Theta_2_1_0: 0.27795605 -1.23858111 -3.34559697\n",
      "Epoch: 987 Loss: 0.06287726   Theta_2_1_0: 0.27868085 -1.23696070 -3.34760360\n",
      "Epoch: 988 Loss: 0.06280557   Theta_2_1_0: 0.27940373 -1.23534792 -3.34960859\n",
      "Epoch: 989 Loss: 0.06273422   Theta_2_1_0: 0.28012467 -1.23374275 -3.35161196\n",
      "Epoch: 990 Loss: 0.06266321   Theta_2_1_0: 0.28084369 -1.23214518 -3.35361371\n",
      "Epoch: 991 Loss: 0.06259253   Theta_2_1_0: 0.28156078 -1.23055517 -3.35561385\n",
      "Epoch: 992 Loss: 0.06252218   Theta_2_1_0: 0.28227595 -1.22897271 -3.35761238\n",
      "Epoch: 993 Loss: 0.06245217   Theta_2_1_0: 0.28298920 -1.22739776 -3.35960930\n",
      "Epoch: 994 Loss: 0.06238248   Theta_2_1_0: 0.28370054 -1.22583032 -3.36160462\n",
      "Epoch: 995 Loss: 0.06231312   Theta_2_1_0: 0.28440996 -1.22427034 -3.36359835\n",
      "Epoch: 996 Loss: 0.06224408   Theta_2_1_0: 0.28511748 -1.22271782 -3.36559048\n",
      "Epoch: 997 Loss: 0.06217537   Theta_2_1_0: 0.28582310 -1.22117272 -3.36758103\n",
      "Epoch: 998 Loss: 0.06210697   Theta_2_1_0: 0.28652682 -1.21963502 -3.36957000\n",
      "Epoch: 999 Loss: 0.06203889   Theta_2_1_0: 0.28722864 -1.21810470 -3.37155739\n",
      "Epoch: 1000 Loss: 0.06197113   Theta_2_1_0: 0.28792857 -1.21658173 -3.37354321\n"
     ]
    }
   ],
   "source": [
    "# Use the below line in Jupyter Notebook to view the plot with interactive window, it doesn't work in Google Colab\n",
    "%matplotlib qt\n",
    "# Set limits for 2 axises so that the plot keeps drawing only in a certain space\n",
    "plt.xlim(-15, 8)\n",
    "plt.ylim(-10, 15)\n",
    "\n",
    "plt.plot(x_blue[0][:], x_blue[1][:], 'bo')\n",
    "plt.plot(x_red[0][:], x_red[1][:], 'ro')\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "count_epoch = 1\n",
    "epoch = 1000\n",
    "while True:\n",
    "    # Calculate loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = Loss(theta)\n",
    "        \n",
    "    # Draw a line using theta to see how the algorithm is doing\n",
    "    x_vis = np.array([[-15], [15]])  # vis stand for visualize\n",
    "    y_vis = -(theta[1][0]*x_vis + theta[0][0]) / theta[2][0]\n",
    "    plt.plot(x_vis, y_vis)\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "    # Update theta\n",
    "    grads = tape.gradient(loss, [theta])\n",
    "    opt.apply_gradients(zip(grads, [theta]))\n",
    "    print(\"Epoch: %d Loss: %.8f   Theta_2_1_0: %.8f %.8f %.8f\" %(count_epoch, loss.numpy(), theta[2][0], theta[1][0], theta[0][0]))\n",
    "\n",
    "    # Stopping condition\n",
    "    # Check if all values in loss is less than epsilon\n",
    "    # It will probably take a long time to satisfy the above condition, so we will have to use epoch\n",
    "    if tf.experimental.numpy.all((tf.math.abs(grads) < epsilon)) or count_epoch == epoch:\n",
    "        break\n",
    "    count_epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ75hE4HuF4l"
   },
   "source": [
    "**Result:** theta after running Losgistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1634034665797,
     "user": {
      "displayName": "Hieu Le Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07970718141756542178"
     },
     "user_tz": -420
    },
    "id": "YJIvU2AkuK3g",
    "outputId": "698092b3-bdea-4997-fd54-5ab9de121db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current optimal value of theta_0: -3.3735432143021264\n",
      "Current optimal value of theta_1: -1.2165817294860075\n",
      "Current optimal value of theta_1: 0.28792856671370876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current optimal value of theta_0: {theta[0][0]}\")\n",
    "print(f\"Current optimal value of theta_1: {theta[1][0]}\")\n",
    "print(f\"Current optimal value of theta_1: {theta[2][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634034667197,
     "user": {
      "displayName": "Hieu Le Trung",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07970718141756542178"
     },
     "user_tz": -420
    },
    "id": "7iWh5vD4_pJY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNd9EBE3RqeCZo6coQz6Ecz",
   "collapsed_sections": [],
   "name": "LogisticRegression_Tensorflow[Upgrade].ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
